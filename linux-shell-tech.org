
* shell 调试技术

http://www.ibm.com/developerworks/cn/linux/l-cn-shell-debug/

http://bashdb.sourceforge.net/
http://www.gnu.org/software/bash/bash.html

/
trap命令：

trap 'command' signal 
---------------------------------------------------------- 
signal 	何时产生
EXIT	从一个函数中退出或整个脚本执行完毕
ERR	当一条命令返回非零状态时(代表命令执行不成功)
DEBUG	脚本中每一条命令执行之前
--------------------------------------------------------

通过捕获EXIT信号,我们可以在shell脚本中止执行或从函数中退出时，输出某些想要跟踪的变量的值，并由此来判断脚本的执行状态以及出错原因,其使用方法是：
trap 'command' EXIT　或　trap 'command' 0
----------------------------------------------------------
$ cat -n exp1.sh
     1  ERRTRAP()
     2  {
     3    echo "[LINE:$1] Error: Command or function exited with status $?"
     4  }
     5  foo()
     6  {
     7    return 1;
     8  }
     9  trap 'ERRTRAP $LINENO' ERR
    10  abc
    11  foo
      ----------------------------------



在调试过程中，为了跟踪某些变量的值，我们常常需要在shell脚本的许多地方插入相同的echo语句来打印相关变量的值，这种做法显得烦琐而笨拙。而通过捕获DEBUG信号，我们只需要一条trap语句就可以完成对相关变量的全程跟踪。

以下是一个通过捕获DEBUG信号来跟踪变量的示例程序:

$ cat –n exp2.sh
     1  #!/bin/bash
     2  trap 'echo “before execute line:$LINENO, a=$a,b=$b,c=$c”' DEBUG
     3  a=1
     4  if [ "$a" -eq 1 ]
     5  then
     6     b=2
     7  else
     8     b=1
     9  fi
    10  c=3
    11  echo "end"


其输出结果如下：

$ sh exp2.sh
before execute line:3, a=,b=,c=
before execute line:4, a=1,b=,c=
before execute line:6, a=1,b=,c=
before execute line:10, a=1,b=2,c=
before execute line:11, a=1,b=2,c=3
end

使用tee命令 

tee命令会从标准输入读取数据，将其内容输出到标准输出设备,同时又可将内容保存成文件，可以查看临时输出的内容
ipaddr=`/sbin/ifconfig | grep 'inet addr:' | grep -v '127.0.0.1' | cut -d : -f3 | awk '{print $1}'` 

ipaddr=`/sbin/ifconfig | grep 'inet addr:' | grep -v '127.0.0.1' | tee temp.txt | cut -d : -f3 | awk '{print $1}'`
$ cat temp.txt
inet addr:192.168.0.1  Bcast:192.168.0.255  Mask:255.255.255.0


调试钩子
$ cat –n exp3.sh
     1  debug()
     2  {
     3  if [ "$DEBUG" = "true" ]; then
     4      $@　　 # $@ 代表debug 函数的所有参数，通过DEBUG变量 可以控制是否输出调试信息
     5  fi
     6  }
     7  a=1
     8  debug echo "a=$a"
     9  if [ "$a" -eq 1 ]
    10  then
    11       b=2
    12  else
    13       b=1
    14  fi
    15  debug echo "b=$b"
    16  c=3
    17  debug echo "c=$c"


使用shell的执行选项

-e exit if error
-n 只读取shell脚本，但不实际执行
-x 进入跟踪方式，显示所执行的每一条命令
-c "string" 从strings中读取命令

“-n”可用于测试shell脚本是否存在语法错误，但不会实际执行命令。在shell脚本编写完成之后，实际执行之前，首先使用“-n”选项来测试脚本是否存在语法错误是一个很好的习惯。因为某些shell脚本在执行时会对系统环境产生影响，比如生成或移动文件等，如果在实际执行才发现语法错误，您不得不手工做一些系统环境的恢复工作才能继续测试这个脚本。

“-c”选项使shell解释器从一个字符串中而不是从一个文件中读取并执行shell命令。当需要临时测试一小段脚本的执行结果时，可以使用这个选项，如下所示：
sh -c 'a=1;b=2;let c=$a+$b;echo "c=$c"'

"-x"选项可用来跟踪脚本的执行，是调试shell脚本的强有力工具。“-x”选项使shell在执行脚本的过程中把它实际执行的每一个命令行显示出来，并且在行首显示一个"+"号。 "+"号后面显示的是经过了变量替换之后的命令行的内容，有助于分析实际执行的是什么命令。 “-x”选项使用起来简单方便，可以轻松对付大多数的shell调试任务,应把其当作首选的调试手段。

如果把本文前面所述的trap ‘command’ DEBUG机制与“-x”选项结合起来，我们就可以既输出实际执行的每一条命令，又逐行跟踪相关变量的值，对调试相当有帮助。

仍以前面所述的exp2.sh为例，现在加上“-x”选项来执行它：

$ sh –x exp2.sh
+ trap 'echo "before execute line:$LINENO, a=$a,b=$b,c=$c"' DEBUG
++ echo 'before execute line:3, a=,b=,c='
before execute line:3, a=,b=,c=
+ a=1
++ echo 'before execute line:4, a=1,b=,c='
before execute line:4, a=1,b=,c=
+ '[' 1 -eq 1 ']'
++ echo 'before execute line:6, a=1,b=,c='
before execute line:6, a=1,b=,c=
+ b=2
++ echo 'before execute line:10, a=1,b=2,c='
before execute line:10, a=1,b=2,c=
+ c=3
++ echo 'before execute line:11, a=1,b=2,c=3'
before execute line:11, a=1,b=2,c=3
+ echo end
end


在上面的结果中，前面有“+”号的行是shell脚本实际执行的命令，前面有“++”号的行是执行trap机制中指定的命令，其它的行则是输出信息。

shell的执行选项除了可以在启动shell时指定外，亦可在脚本中用set命令来指定。 "set -参数"表示启用某选项，"set +参数"表示关闭某选项。有时候我们并不需要在启动时用"-x"选项来跟踪所有的命令行，这时我们可以在脚本中使用set命令，如以下脚本片段所示：

set -x　　　 #启动"-x"选项 
要跟踪的程序段 
set +x　　　　 #关闭"-x"选项


set命令同样可以使用上一节中介绍的调试钩子—DEBUG函数来调用，这样可以避免脚本交付使用时删除这些调试语句的麻烦，如以下脚本片段所示：

DEBUG set -x　　　 #启动"-x"选项 
要跟踪的程序段 
DEBUG set +x　　　 #关闭"-x"选项

四. 对"-x"选项的增强

，下面先介绍几个shell内置的环境变量：

$LINENO
代表shell脚本的当前行号，类似于C语言中的内置宏__LINE__

$FUNCNAME
函数的名字，类似于C语言中的内置宏__func__,但宏__func__只能代表当前所在的函数名，而$FUNCNAME的功能更强大，它是一个数组变量，其中包含了整个调用链上所有的函数的名字，故变量${FUNCNAME[0]}代表shell脚本当前正在执行的函数的名字，而变量${FUNCNAME[1]}则代表调用函数${FUNCNAME[0]}的函数的名字，余者可以依此类推。

$PS4
主提示符变量$PS1和第二级提示符变量$PS2比较常见，但很少有人注意到第四级提示符变量$PS4的作用。我们知道使用“-x”执行选项将会显示 shell脚本中每一条实际执行过的命令，而$PS4的值将被显示在“-x”选项输出的每一条命令的前面。在Bash Shell中，缺省的$PS4的值是"+"号。(现在知道为什么使用"-x"选项时，输出的命令前面有一个"+"号了吧？)。

利用$PS4这一特性，通过使用一些内置变量来重定义$PS4的值，我们就可以增强"-x"选项的输出信息。例如先执行export PS4='+{$LINENO:${FUNCNAME[0]}} ', 然后再使用“-x”选项来执行脚本，就能在每一条实际执行的命令前面显示其行号以及所属的函数名。

以下是一个存在bug的shell脚本的示例，本文将用此脚本来示范如何用“-n”以及增强的“-x”执行选项来调试shell脚本。这个脚本中定义了一个函数isRoot(),用于判断当前用户是不是root用户，如果不是，则中止脚本的执行

$ cat –n exp4.sh
     1  #!/bin/bash
     2  isRoot()
     3  {
     4          if [ "$UID" -ne 0 ]
     5                  return 1
     6          else
     7                  return 0
     8          fi
     9  }
    10  isRoot
    11  if ["$?" -ne 0 ]
    12  then
    13          echo "Must be root to run this script"
    14          exit 1
    15  else
    16          echo "welcome root user"
    17          #do something
    18  fi


首先执行sh –n exp4.sh来进行语法检查，输出如下：

$ sh –n exp4.sh
exp4.sh: line 6: syntax error near unexpected token `else'
exp4.sh: line 6: `      else'


发现了一个语法错误，通过仔细检查第6行前后的命令，我们发现是第4行的if语句缺少then关键字引起的(写惯了C程序的人很容易犯这个错误)。我们可以把第4行修改为if [ "$UID" -ne 0 ]; then来修正这个错误。再次运行sh –n exp4.sh来进行语法检查，没有再报告错误。接下来就可以实际执行这个脚本了，执行结果如下：

$ sh exp4.sh
exp2.sh: line 11: [1: command not found
welcome root user


尽管脚本没有语法错误了，在执行时却又报告了错误。错误信息还非常奇怪“[1: command not found”。现在我们可以试试定制$PS4的值，并使用“-x”选项来跟踪：

$ export PS4='+{$LINENO:${FUNCNAME[0]}} '
$ sh –x exp4.sh
+{10:} isRoot
+{4:isRoot} '[' 503 -ne 0 ']'
+{5:isRoot} return 1
+{11:} '[1' -ne 0 ']'
exp4.sh: line 11: [1: command not found
+{16:} echo 'welcome root user'
welcome root user


从输出结果中，我们可以看到脚本实际被执行的语句，该语句的行号以及所属的函数名也被打印出来，从中可以清楚的分析出脚本的执行轨迹以及所调用的函数的内部执行情况。由于执行时是第11行报错，这是一个if语句，我们对比分析一下同为if语句的第4行的跟踪结果：

+{4:isRoot} '[' 503 -ne 0 ']'
+{11:} '[1' -ne 0 ']'


可知由于第11行的[号后面缺少了一个空格，导致[号与紧挨它的变量$?的值1被shell解释器看作了一个整体，并试着把这个整体视为一个命令来执行，故有“[1: command not found”这样的错误提示。只需在[号后面插入一个空格就一切正常了。

shell中还有其它一些对调试有帮助的内置变量，比如在Bash Shell中还有BASH_SOURCE, BASH_SUBSHELL等一批对调试有帮助的内置变量，您可以通过man sh或man bash来查看，然后根据您的调试目的,使用这些内置变量来定制$PS4，从而达到增强“-x”选项的输出信息的目的。 





** 删除文件名中的空格
ls |while read i;do
        mv "$i" $(echo $i|tr -d ' ') 2>/dev/null
done
--------------------------------------------------------------------------------

 
** sudo不输入密码
/etc/sudoers
username1 ALL= NOPASSWD: /path/to/command
####表示username1用户在执行/path/to/command命令时不用输入passwd 

** expect和spawn

* history 配置和命令手册
** 配置在~/.bashrc中
####HISTTIMEFORMATIf this variable is set and not null, its value is used as a format string for strftime(3) to print  the
###time  stamp  associated  with  each history entry displayed by the history builtin.  If this variable is
###set, time stamps are written to the history file so they may be preserved across shell sessions.
export HISTTIMEFORMAT="%T %F "
export HISTSIZE=9999
export HISTFILESIZE=9999
####the entry of history should not be too big, because every time shell start it will read
###the history entry into its memory, so if it's big there are many overheads on it.
###we can save it in some other log files, so shell won't load it everytime shell startup
###while there's log to trace.

*** 使用 HISTTIMEFORMAT 显示时间戳

当你从命令行执行 history 命令后，通常只会显示已执行命令的序号和命令本身。如果你想要查看命令历史的时间戳，那么可以执行：

# export HISTTIMEFORMAT='%F %T '
# history | more
1 2008-08-05 19:02:39 service network restart
2 2008-08-05 19:02:39 exit
3 2008-08-05 19:02:39 id
4 2008-08-05 19:02:39 cat /etc/redhat-release


*** 使用 HISTSIZE 控制历史命令记录的总行数

将下面两行内容追加到 .bash_profile 文件并重新登录 bash shell，命令历史的记录数将变成 450 条：

# vi ~/.bash_profile
HISTSIZE=450
HISTFILESIZE=450

*** 使用 HISTFILE 更改历史文件名称

默认情况下，命令历史存储在 ~/.bash_history 文件中。添加下列内容到 .bash_profile 文件并重新登录 bash shell，将使用 .commandline_warrior 来存储命令历史：

# vi ~/.bash_profile
HISTFILE=/root/.commandline_warrior

*** 使用 HISTCONTROL 从命令历史中剔除连续重复的条目

在下面的例子中，pwd 命令被连续执行了三次。执行 history 后你会看到三条重复的条目。要剔除这些重复的条目，你可以将 HISTCONTROL 设置为 ignoredups：

# pwd
# pwd
# pwd
# history | tail -4
44 pwd
45 pwd
46 pwd [Note that there are three pwd commands in history, after executing pwd 3 times as shown above]
47 history | tail -4
# export HISTCONTROL=ignoredups
# pwd
# pwd
# pwd
# history | tail -3
56 export HISTCONTROL=ignoredups
57 pwd [Note that there is only one pwd command in the history, even after executing pwd 3 times as shown above]
58 history | tail -4

*** 使用 HISTCONTROL 清除整个命令历史中的重复条目

上例中的 ignoredups 只能剔除连续的重复条目。要清除整个命令历史中的重复条目，可以将 HISTCONTROL 设置成 erasedups：

# export HISTCONTROL=erasedups
# pwd
# service httpd stop
# history | tail -3
38 pwd
39 service httpd stop
40 history | tail -3
# ls -ltr
# service httpd stop
# history | tail -6
35 export HISTCONTROL=erasedups
36 pwd
37 history | tail -3
38 ls -ltr
39 service httpd stop
[Note that the previous service httpd stop after pwd got erased]
40 history | tail -6

*** 使用 HISTCONTROL 强制 history 不记住特定的命令

将 HISTCONTROL 设置为 ignorespace，并在不想被记住的命令前面输入一个空格：

# export HISTCONTROL=ignorespace # ls -ltr # pwd # service httpd stop [Note that there is a
space at the beginning of service, to ignore this command from history] # history | tail -3 67 ls
-ltr 68 pwd 69 history | tail -3

*** 使用 HISTSIZE 禁用 history

如果你想禁用 history，可以将 HISTSIZE 设置为 0：

# export HISTSIZE=0
# history
# [Note that history did not display anything]

*** 使用 HISTIGNORE 忽略历史中的特定命令

下面的例子，将忽略 pwd、ls、ls -ltr 等命令：

# export HISTIGNORE=”pwd:ls:ls -ltr:”
# pwd
# ls
# ls -ltr
# service httpd stop
# history | tail -3
79 export HISTIGNORE=”pwd:ls:ls -ltr:”
80 service httpd stop
81 history
[Note that history did not record pwd, ls and ls -ltr]



***  使用 -c 选项清除所有的命令历史

如果你想清除所有的命令历史，可以执行：

# history -c




** history related command
*** history parameter
　　[test@linux]# history [n](by default, history List the last 16 commands)
　　[test@linux]# history [-c]
　　[test@linux]# history [-raw] histfiles
　
　　n ：number,n entries of history command
######-c will clear every shell's own history memory
　　-c ：将目前的shell中的所有 history 内容全部消除
######## -a,-r,-w is for filesystem,default～/.bash_history　
　-a ：将目前新增的history 指令新增入 histfiles 中，若没有加 histfiles ，
　　则预设写入 ~/.bash_history
　　-r ：将 histfiles 的内容读到目前这个 shell 的 history 记忆中
　　-w ：将目前的 history 记忆内容写入 histfiles


*** fc command
fc -l 20 30 List commands 20 through 30

fc -l -5 List the last five commands

fc -l cat List the last command beginning with cat

fc -ln 5 > doit Save command 5 to file doit

fc -e vi 5 20 Edit commands 5 through 20 using vi

fc -e emacs Edit previous command using Emacs 




** sync two terminal's commands history
if there are multi terminals running simutonlously, the last exiting one will
overwrite all the history file, if histappend switch is off.
# shopt -s hisappend
to turn on the append switch


*** using history -a manually
if you want to synchronize all the terminals history command, you could
use history -a
###terminal A
 lily@willow:~$ echo "make a stamp in term a"
make a stamp in term a
lily@willow:~$ history -a
###################terminal B
####original history
lily@willow:~$ history 5
   35  17:02:38 2012-03-02 history -a
   36  17:10:44 2012-03-02 echo "terama  dfdfdfd"
   37  17:10:47 2012-03-02 history -a
   38  17:11:02 2012-03-02 history
   39  17:11:12 2012-03-02 history 5
##########history after term A echo 
lily@willow:~$ history 5
   35  17:02:38 2012-03-02 history -a
   36  17:10:44 2012-03-02 echo "terama  dfdfdfd"
   37  17:10:47 2012-03-02 history -a
   38  17:11:02 2012-03-02 history
   39  17:11:12 2012-03-02 history 5
#########after use history -a in A terminal,Then use history -r in shell B,
lily@willow:~$ history -r
lily@willow:~$ history 5
   56  17:10:44 2012-03-02 echo "terama  dfdfdfd"
   57  17:10:47 2012-03-02 history -a
   58  17:11:37 2012-03-02 echo "make a stamp in term a"
#####we got this echo in terminal A
   59  17:11:42 2012-03-02 history -a
   60  17:12:00 2012-03-02 history 5
lily@willow:~$ 

*** use enviroment variable in PROMPT_COMMAND
apend the history -a to the prompt_command
export PROMPT_COMMAND="history -a;$PROMPT_COMMAND"
or you can add this to .bashrc

** how to repeat last executed command 
*** $ CTRl+R 使用 Ctrl+R 搜索历史
type into the command, it will search the latest matching command 
then continue CTRL+R, it will navigate all the matching pattern
enter the one you want, or use left/right arrow key to edit it 

Ctrl+R 是我经常使用的一个快捷键。此快捷键让你对命令历史进行搜索，对于想要重复执行某个命令的时候非常有用。当找到命令后，通常再按回车键就可以执行该命令。如果想对找到的命令进行调整后再执行，则可以按一下左或右方向键。

# [Press Ctrl+R from the command prompt, which will display the reverse-i-search prompt]
(reverse-i-search)`red‘: cat /etc/redhat-release
[Note: Press enter when you see your command, which will execute the command from the history]
# cat /etc/redhat-release
Fedora release 9 (Sulphur)

*** [!number]  exeute a history command from number 

# history | more
1 service network restart
2 exit
3 id
4 cat /etc/redhat-release
# !4
cat /etc/redhat-release
Fedora release 9 (Sulphur)

!N 
Reexecute Command number N in history list.
!-N 
Reexecute Nth command back from current command.


12. 命令替换

在下面的例子里，将为当前的命令获得上一条命令的参数：

13. 为特定的命令替换指定的参数

下例里，!cp:$ 获取 cp 命令的最后一项参数：

# ls -l !cp:$
ls -l /really/a/very/long/path/long-filename.txt



*** [!command][!!]
!commandname 
will execute the last command 
!!
 Reexecute previous command
!cat 
Reexecute last cat command
!cat foo-file
 Reexecute last command, adding foo-file to the end of the argument list
# !ps
ps aux | grep yp
root 16947 0.0 0.1 36516 1264 ? Sl 13:10 0:00 ypbind
root 17503 0.0 0.0 4124 740 pts/0 S+ 19:19 0:00 grep yp


*** get argument of previous command
!:*    ----get all argument

!:[number] ---get nth argument
the number argument
!:1 first argument


!$   ----  Last argument of previous command. 
#########
lily@willow:~$ emacs linux-shell-tech.org
lily@willow:~$ echo !$
echo linux-shell-tech.org
linux-shell-tech.org
lily@willow:~$ 
#######

!^ ----  first argument of previous command 
# cp anaconda-ks.cfg anaconda-ks.cfg.bak
anaconda-ks.cfg
# vi -5 !^
vi anaconda-ks.cfg

**** get argument from specified command
![command]:[number]
!cp:2 从命令历史中搜索以 cp 开头的命令，并获取它的第二项参数：

# cp ~/longname.txt /really/a/very/long/path/long-filename.txt
# ls -l !cp:2
ls -l /really/a/very/long/path/long-filename.txt










==================================
add timestamp/date before everyline of the shell output
---------------------------------------------------
[liguo@walnut addtime]$ (echo a;sleep 5;echo b; sleep 2;echo c)|./predate.sh
Fri Sep  7 16:31:27 CST 2012: a
Fri Sep  7 16:31:32 CST 2012: b
Fri Sep  7 16:31:34 CST 2012: c
[liguo@walnut addtime]$ cat predate.sh
#!/bin/bash
while read line ; do
    echo "$(date): ${line}"
done
[liguo@walnut addtime]$
--------------------------------------------------------------
( myscript.sh 3>&1 1>&2- 2>&3- ) | ./predate.sh >error.log





用grep命令统计字符串出现的次数

使用如下形式来统计变量$x中s字符出现的次数：
x="This is a test"
grep -o "s" <<<"$x" | wc -l

你可以使用如下的Bash参数来实现：

x="This is a test"
y="${x//[^s]}"
echo "$y"
echo "${#y}"
要匹配s和S，输入如下：
x="This is a test. S"
y="${x//[^s|S]}"
echo "${#y}"

get a date from system
date +%Y


putty
我常用的putty配置选项
Posted by zuzhihui in vps技术 on 2008/10/11 with 2 Comments

Putty是个非常好用的ssh客户端软件。当然要先配置好putty，使用起来才能方便，配置不好的话，或许你不会喜欢它。 本文介绍我常用的putty配置选项。

配置putty首先在配置窗口选择”Default Settings”这个配置方案，然后点击load把这个配置方案调出来，然后依次按照下面的进行配置。注意配置完成之后要重新选择”Default Settings”这个配置方案，然后点击save把刚才配置的东西保存到”Default Settings”这个配置方案。这样以后新建立的连接都会采用”Default Settings”里面的各项设置了。

需要配置的选项为：

Window -> Lines of scrollback 20000   –  让putty窗口的缓冲区大一些，这样在使用的时候好翻看putty的历史
Window -> appearance: Font Fixedsys 12 points   –  选择这个字体可以更好显示中文
Window -> translation: select UTF-8 in the dropdown menu    –  很多linux的编码都是UTF-8，选择该项目才能够支持linux的utf8。如果Linux没有使用UTF-8，则不要选择该项
Connection -> seconds between keepalives 60   –  心跳，长时间没有操作的话，能够保证不断开
Connection -> SSH -> auth: Allow agent forwarding   –  这个是SSH的一个高级选项，不多解释了，可以不配置
Connection -> SSH -> auth: Private key file   –  这个是SSH的一个高级选项，不多解释了，可以不配置，如果是使用Putty Session Manager那就更没有必要配置该项了
Connection -> SSH -> Tunnels — 这个也是高级选项，SSH隧道，用来做代理用的，Source Port写7070，下面选择Dynamic然后点击Add即可，详见： http://rashost.com/blog/putty-ssh-tunnel
配置完成之后，不要忘了按照本文前面的方法保存配置。另外，推荐 http://rashost.com/blog/putty-session-manager 来配合Putty使用，非常方便
默认的快捷键主要有: F2: new window , F3/F4: switch , F5 reload, F6: Detach, F7: 回滚模式, F8: rename, F12:lockscreen

如果你用的是 putty, 它默认的按键绑定跟 byobu 的冲突. 在 putty的 Terminal => Keyboard 配置里选 "Xterm R6" 后保存, 上面的快捷键就都可以用了

它默认的配置最底部左边是发行版信息, 右边是cpu等信息, 倒数第2行左边是窗口列表, 右边是登陆信息. 觉得它下边占了两行太浪费了, 我希望只占一行, 左边是窗口列表, 右边是 cpu等信息. 所以需要改它的profile 文件:

sudo vi ~/.byobu/profile

在这个文件最后找到 hardstatus 和 caption 开头的那两行, 注释掉, 然后加入两行:

hardstatus ignore
udo vi ~/.byobu/profileaption always '%12`%?%-Lw%50L>%?%{=r}%n*%f %t%?(%u)%?%{-}%12`%?%+Lw%?%11` %= %130`%135`%102`%101`%129`%131`%127`%114`%115`%108`%134`%128`%125`%126`%113`%119`%133`%117`%116`%106`%104`%103`%105`%107`%136`%123`%132`%120`%121`'

同目录下还有个 status 文件, 定义了哪些信息需要在右下角显示. 
编辑完后按 F5 刷新配置文件, 显示如下图:

使用过程中还发现点问题. 你用 byobu -S yc 新建一个 session, 用完后按 F6 detach, 然后恢复的时候不能象 screen 那样用 -r 参数恢复. 查了下, 原来 byobu 使用了它自己默认的 -S byobu

所以需要对 byobu 脚本做点修改:
sudo vi `which byobu`

找到 NAME="-S $PKG" 那行 (79行左右), 在下面加入一句:
[ "$#" = "2" ] && [ "$1" = "-r" ] && NAME=

意思是当指定了 -r 参数时不用 byobu 它自己的名字. 这样就可以用 -r 来恢复session 了:w

xming and putty for x11 forwarding
1. installl xming in windows
2. install putty in windows and set the ssh option, enbale Connection->SSH->X11 
Enable X11 forwarding
X display location : localhost:0
the number is which displayed in xming at the right bottom
3. /etc/ssh/sshd_config
X11Forwarding yes
4. ssh into the host using putty and type gedit
if no window pop out for gedit
Gtk_WARNING **: cannot open display:
echo $DISPLAY 
localhost:10.0
the problem is that localhost could be misunderstood if some host's hostname is localhost.
so shouldbe 127.0.0.1:10.0
export DISPLAY=127.0.0.1
gedit will succssefully open in another window
DISPLAY format:
 hostname:displaynumber.screennumber 


if access windows Xming.exe faile 
refuesed by server
add the -ac parameter when ximg launch
Xming.exe :0 -clipboard -multiwindow  
Xming.exe -ac :0 -clipboard -multiwindow  

wall  ---send message to all the terminal user

* shell 变量和数组

参考文档：   http://bbs.chinaunix.net/viewthread.php?tid=218853&page=7#pid1617953
http://bbs.chinaunix.net/thread-746472-1-1.html
http://bbs.chinaunix.net/viewthread.php?tid=1765539
一  关于变量名
在 bash file replace with - in shell 中，$( ) 與 ` ` (反引號) 都是用來做命令替換用(command substitution)的。
$ echo the last sunday is $(date -d "last sunday" +%Y-%m-%d)
the last sunday is 2011-04-10
$ echo the last sunday is `date -d "last sunday" +%Y-%m-%d`
the last sunday is 2011-04-10

多层嵌套
command1 `command2 \`command3\` `     注意 转意  \
command1 $(command2 $(command3))
----------------------
 $ A=B
 $ echo ${A}B
    BB
$ echo $AB
空，未定义AB变量
--------------------------------

删除某字符以左/右的全不字符： #  %  ## %%
-------------------------------------------
zxx@zxx-desktop:~$ echo ${file}
rest/dir1/dir2/dir2/my.file.txt
zxx@zxx-desktop:~$ echo ${file#*/}       #表示从左边删除  符号/以左的所有字符包括/
dir1/dir2/dir2/my.file.txt
zxx@zxx-desktop:~$ echo ${file#*.}        #表示从左边删除  符号.以左的所有字符包括.
file.txt
zxx@zxx-desktop:~$ echo ${file##*.}         ##表示最大匹配，符号.以左的所有字符包括.
txt
-------------------------------------------------------------

zxx@zxx-desktop:~$ echo ${file%/*}              %表示从右边删除  符号/以右的所有字符包括/
rest/dir1/dir2/dir2
zxx@zxx-desktop:~$ echo ${file%%/*}        %%最大匹配从右边删除  符号/以右的所有字符包括/
rest
zxx@zxx-desktop:~$
-------------------------------------------------------------------

取变量var从第nth个字符开始后num个字符  ${var:nth:num}
------------------------------------------------------


取变量var从第nth个字符开始后num个字符  ${var:nth:num}
------------------------------------------------------

zxx@zxx-desktop:~$ echo ${file:2:2}
st
zxx@zxx-desktop:~$ echo ${file:0:2}
re
zxx@zxx-desktop:~$ echo ${file:0:4}
rest
zxx@zxx-desktop:~$
-----------------------------------------------------------------------------------------------------

替换变量里var的字符strsource为strreplace   ${var/strsource/strreplace}
全部替换变量里的字符  ${var//strsource/strreplace}
------------------------------------
zxx@zxx-desktop:~$ echo ${file/dir/path}
rest/path1/dir2/dir2/my.file.txt
zxx@zxx-desktop:~$ echo ${file//dir/path}
rest/path1/path2/path2/my.file.txt
zxx@zxx-desktop:~$
-----------------------------------
${#var} 可計算出變量值的長度：
---------------------
zxx@zxx-desktop:~$ echo ${#file}
31
----------------

for i in *.jpg;  do mv $i ${i%.jpg}_MED.jpg; done

利用 ${ } 還可針對不同的變數狀態賦值(沒設定、空值、非空值)：
${file-my.file.txt} ：假如 $file 沒有設定，則使用 my.file.txt 作傳回值。(空值及非空值時不作處理)
${file:-my.file.txt} ：假如 $file 沒有設定或為空值，則使用 my.file.txt 作傳回值。 (非空值時不作處理)
${file+my.file.txt} ：假如 $file 設為空值或非空值，均使用 my.file.txt 作傳回值。(沒設定時不作處理)
${file:+my.file.txt} ：若 $file 為非空值，則使用 my.file.txt 作傳回值。 (沒設定及空值時不作處理)
${file=my.file.txt} ：若 $file 沒設定，則使用 my.file.txt 作傳回值，同時將 $file 賦值為 my.file.txt 。 (空值及>非空值時不作處理)
${file:=my.file.txt} ：若 $file 沒設定或為空值，則使用 my.file.txt 作傳回值，同時將 $file 賦值為 my.file.txt 。
 (非空值時不作處理)
${file?my.file.txt} ：若 $file 沒設定，則將 my.file.txt 輸出至 STDERR。 (空值及非空值時不作處理)
${file:=my.file.txt} ：若 $file 沒設定或為空值，則使用 my.file.txt 作傳回值，同時將 $file 賦值為 my.file.txt 。
 (非空值時不作處理)
${file?my.file.txt} ：若 $file 沒設定，則將 my.file.txt 輸出至 STDERR。 (空值及非空值時不作處理)
${file:?my.file.txt} ：若 $file 沒設定或為空值，則將 my.file.txt 輸出至 STDERR。 (非空值時不作處理
在shell命令中，开头相似的可以用digit{1,2,}这表示
digit1 digit2 digit
比如重命名：mv file{,.bak}这表示
mv file file.bak


* shell command line argument
---------------
echo "how much parameters are:"
echo "$@"
##all the argument list not including the execute file iteself
echo "the first of all command line is $0"
## means the first one of the whole command line, it's the exectue file
echo "the first argu is ${@:0}"
## means the while list of argument
echo "the second argu is ${@:1}"
## means the first argument posision
echo "the third argu is ${@:2}"
## means the second argument posision
echo "the third argu is ${@:3}"
## means the third argument posision
--------------------------
guolili@TTCN ~/test/cc
$./t.sh 1 2 3
how much parameters are:
1 2 3
the first of all command line is ./t.sh
the first argu is 1 2 3
the second argu is 1 2 3
the third argu is 2 3
the third argu is 3
--------------------

* shell 命令 的 版本

ubuntu 就将先前默认的bash file replace with - in shell 更换成了dash file replace with - in shell；其表现为 /bin
/sh 链接倒了/bin/dash而不是传统的/bin/bash。

ubuntu edgy是第一个将dash作为默认shell来发行的版本，这似乎是受了debian的影响。wiki 里面有官方的解释，https://wiki.ubuntu.com/DashAsBinSh，主要原因是dash更小，运行更快，还与POSIX兼容。

但目前存在的问题是，由于shell的更换，致使很多脚本出错，毕竟现在的很多脚本不是100%POSIX兼容。

在wiki里面也说到，如何将默认的shell改回bash，方法就是

在终端执行 sudo dpkg-reconfigure dash

然后选择 no。


* bash 中的递归 函数

http://www.ibm.com/developerworks/cn/linux/l-cn-bashrecur/index.html
sed 使用手册
http://socol.iteye.com/blog/518864


* add user
useradd -d /home/username -m username
有时新建的用户的shell没有tab和上下键功能，这时shell的版本不对，
可以用ls -l /bin/sh 查看实际shell的位置，一般用bash shell
将 ln -sf /bin/bash /bin/sh

xxx is not in the sudoers file解决方法
用sudo时提示"xxx is not in the sudoers file. This incident will be reported.其中XXX是你的用户名，也就是你的用户名没有权限使用sudo,我们只要修改一下/etc/sudoers文件就行了。

1.下面是修改方法：


1）进入超级用户模式。也就是输入"su -",系统会让你输入超级用户密码，输入密码后就进入了超级用户模式。（当然，你也可以直接用root用） 
2）添加文件的写权限。也就是输入命令"chmod u+w /etc/sudoers"。 
3）编辑/etc/sudoers文件。也就是输入命令"vim /etc/sudoers",输入"i"进入编辑模式，找到这一 行："root ALL=(ALL) ALL"在起下面添加"xxx ALL=(ALL) ALL"(这里的xxx是你的用户名)，然后保存（就是先按一 下Esc键，然后输入":wq"）退出。 
4）撤销文件的写权限。也就是输入命令"chmod u-w /etc/sudoers"。

2.另一种修改sudoers的方法

sudo都提供了一个编辑该文件的命令：visudo来对该文件进行修改。强烈推荐使用该命令修改 sudoers，因为它会帮你校验文件配置是否正确，如果不正确，在保存退出时就会提示你哪段配置出错的。

(改命令需超级用户：su -) visodo /bin/sudoers

3.对sudoers文件详细讲解

A．首先写sudoers的缺省配置： 
###########################################################
# /etc/sudoers
# 
# This file MUST be edited with the 'visudo' command as root. 
# 
# See the sudoers man page for the details on how to write a sudoers file. 
#

Defaults   env_reset
# Host alias specification

# User alias specification

# Cmnd alias specification

# Defaults specification

# User privilege specification 
root    ALL=(ALL) ALL

# Uncomment to allow people in group wheel to run all commands 
# %wheel        ALL=(ALL)       ALL

# Same thing without a password 
# %wheel        ALL=(ALL)       NOPASSWD: ALL

# Samples 
# %users ALL=/sbin/mount /cdrom,/sbin/umount /cdrom 
# %users localhost=/sbin/shutdown -h now 
########################################################

B。最简单的配置，让普通用户ubuntu具有root的所有权限 
执行visudo之后，可以看见缺省只有一条配置：

root    ALL=(ALL) ALL 
那么你就在下边再加一条配置： 
ubuntu ALL=(ALL) ALL 
普通用户ubuntu就能够执行root权限的所有命令。
以ubuntu用户登录之后，执行： 
sudo su - 
然后输入ubuntu用户自己的密码，就可以切换成root用户了。

* linux startup related 
1. boot a system from usb disk

get all the kernel and initial ramdisk from an existing system which 
installed on a hard disk drive.

1.1 make a bootable usb disk
http://wiki.linuxquestions.org/wiki/Booting_from_USB
1.1.1 Connect the USB disk

fdisk /dev/sda
make only one partition and make it bootable

fdisk -l /dev/sda
   Device Boot      Start         End      Blocks   Id  System
/dev/sda1   *           3        7871    15863872   83  Linux

mkfs -t ext3 /dev/sda1


1.1.2 mount usb disk and clone the system
mkdir -p /mnt/sda1
mount /dev/sda1 /mnt/sda1
cd /
tar -c $(ls -1 | grep -Ev "proc|sys|tmp|media|mnt") | (cd /mnt/sda1; tar -xv)
You should know that you will need the /dev folder to create the ramdisk later. You can also use tar -cl (local filesystems only), but that might exclude your /boot partition.

1.1.3 make your USB disk bootable
Here are two possibilities for making the disk bootable, it is not unusual that one fails. Try the uppermost first.
Possibility (1)
$ cd /mnt/sda1
$ chroot .
$ mount /proc
$ grub-install /dev/sda
$ exit
You may have to mknod /dev/sda and /dev/sda1 in the chroot-environment!
Possibility (2)
$ grub-install --recheck --root-directory=/mnt/sda1 /dev/sda
Probing devices to guess BIOS drives. This may take a long time.
Installation finished. No error reported.
This is the contents of the device map /mnt/sda1/boot/grub/device.map.
Check if this is correct or not. If any of the lines is incorrect,
fix it and re-run the script `grub-install'.

(fd0)   /dev/fd0
(hd0)   /dev/hda
(hd1)   /dev/hdb
(hd2)   /dev/sda

1.1.4
Edit your initial ramdisk

The initial ramdisk (initrd) must contain the modules needed to load usb storage. We will use mkinitrd to rebuild your initial ramdisk. First, change to your system on the USB disk:
cd /mnt/sda1
chroot .
mount /proc
Now have a look at the drivers that are loaded by the initial ramdisk.
SUSE
For SUSE, your drivers file is /etc/sysconfig/kernel. You will find a line starting with INITRD_MODULES= in /etc/sysconfig/kernel. It should look like this:
INITRD_MODULES="jbd reiserfs ext3 usbcore usb_storage scsi_mod sd_mod uhci_hcd ehci-hcd sbp2 sr_mod"
it can also contain more modules. Verify this line exists, then, create the initial ramdisk:
mkinitrd
Ubuntu
For Ubuntu, your drivers file is /etc/modules. It should look at least like this (it can also contain more modules):
# /etc/modules: kernel modules to load at boot time.
#
# This file contains the names of kernel modules that should be loaded
# at boot time, one per line. Lines beginning with "#" are ignored.

fuse
lp
usb_storage
uhci_hcd
usbcore
usbhid
sr_mod
sd_mod
scsi_mod
After you verified the file exists, create your initrd with the command:
mkinitramfs -o /boot/initrd.img

1.1.5
Use a unique device name

If you now boot from your USB disk, it might be that it appears under another name than /dev/sda. To circumvent this problem, we will now use the disk's unique ID instead of /dev/sda. Try
hwinfo --partition
You will get a line similar to the following:
  Device Files: /dev/sda1, /dev/disk/by-id/usb-CompanyXXXXXX,_Inc._USB_Mass_Stor
age_Device_100-part1, /dev/disk/by-path/pci-0000:00:1d.7-usb-0:3:1.0-scsi-0:0:0:
0-part1, /dev/disk/by-uuid/84ff6790-9b69-4401-9ba2-43d044af1d30, /dev/disk/by-la
bel/Whatever
Now you know your partition is not only accessible via /dev/sda1, but also via /dev/disk/by-uuid/84ff6790-9b69-4401-9ba2-43d044af1d30.
/etc/fstab
You can now edit the fstab on your USB disk:
kwrite /mnt/sda1/etc/fstab
there is one line for the mountpoint /, maybe:
/dev/sda1               /               ext2            defaults        1  1
In our example, you would change this line to
/dev/disk/by-uuid/84ff6790-9b69-4401-9ba2-43d044af1d30  /   ext2   defaults   1  1
/boot/grub/menu.lst
In /mnt/sda1/boot/grub/menu.lst, you will find some lines telling the kernel where to find the root (/) file system, maybe:
kernel          /boot/vmlinuz-2.6.20-16-generic root=/dev/sda1 ro quiet splash
not to boot from the wrong partition, you can also replace them:
kernel          /boot/vmlinuz-2.6.20-16-generic root=UUID=84ff6790-9b69-4401-9ba2-43d044af1d30 ro quiet splash
Try booting from your disk

If there are problems, continue with TroubleShooting.
TroubleShooting
Error 17 after boot menu
After choosing an item from the grub menu, I get a line saying
Error 17: Cannot mount selected partition
most probably, your device order has changed. For example, if you installed linux from CD and your IDE harddisk was device 0, it may now be device 1 after Booting from USB. In this case change
root (hd1,1)
to
root (hd0,1)
Please note that 1 is simply an example for a partition, it may a


1.2 the starup files related to edit init ramdisk

1.2.1 Anatomy of the initrd

The initrd image contains the necessary executables and system files to support the second-stage boot of a Linux system.
Depending on which version of Linux you're running, the method for creating the initial RAM disk can vary. Prior to Fedora Core 3, the initrd is constructed using the loop device. The loop device is a device driver that allows you to mount a file as a block device and then interpret the file system it represents. The loop device may not be present in your kernel, but you can enable it through the kernel's configuration tool (make menuconfig) by selecting Device Drivers > Block Devices > Loopback Device Support. You can inspect the loop device as follows (your initrd file name will vary):

Listing 1. Inspecting the initrd (prior to FC3)
                
# mkdir temp ; cd temp
# cp /boot/initrd.img.gz .
# gunzip initrd.img.gz
# mount -t ext -o loop initrd.img /mnt/initrd
# ls -la /mnt/initrd
#

You can now inspect the /mnt/initrd subdirectory for the contents of the initrd. Note that even if your initrd image file does not end with the .gz suffix, it's a compressed file, and you can add the .gz suffix to gunzip it.
Beginning with Fedora Core 3, the default initrd image is a compressed cpio archive file. Instead of mounting the file as a compressed image using the loop device, you can use a cpio archive. To inspect the contents of a cpio archive, use the following commands:

Listing 2. Inspecting the initrd (FC3 and later)
                
# mkdir temp ; cd temp
# cp /boot/initrd-2.6.14.2.img initrd-2.6.14.2.img.gz
# gunzip initrd-2.6.14.2.img.gz
# cpio -i --make-directories < initrd-2.6.14.2.img
#

to creat back a cpio archive
#cpio -i -t -F ../ramdisk.img > list
#cpio -o -H newc -O lk.img < list
--------------------------------
the ramdisk.img is the original one file list , 1k.img is the new cpio arcive
------------------------
The result is a small root file system, as shown in Listing 3. The small, but necessary, set of applications are present in the ./bin directory, including nash (not a shell, a script interpreter), insmod for loading kernel modules, and lvm (logical volume manager tools).

Listing 3. Default Linux initrd directory structure 
                
# ls -la
#
drwxr-xr-x  10 root root    4096 May 7 02:48 .
drwxr-x---  15 root root    4096 May 7 00:54 ..
drwxr-xr-x  2  root root    4096 May 7 02:48 bin
drwxr-xr-x  2  root root    4096 May 7 02:48 dev
drwxr-xr-x  4  root root    4096 May 7 02:48 etc
-rwxr-xr-x  1  root root     812 May 7 02:48 init
-rw-r--r--  1  root root 1723392 May 7 02:45 initrd-2.6.14.2.img
drwxr-xr-x  2  root root    4096 May 7 02:48 lib
drwxr-xr-x  2  root root    4096 May 7 02:48 loopfs
drwxr-xr-x  2  root root    4096 May 7 02:48 proc
lrwxrwxrwx  1  root root       3 May 7 02:48 sbin -> bin
drwxr-xr-x  2  root root    4096 May 7 02:48 sys
drwxr-xr-x  2  root root    4096 May 7 02:48 sysroot
#

Of interest in Listing 3 is the init file at the root. This file, like the traditional Linux boot process, is invoked when the initrd image is decompressed into the RAM disk. We'll explore this later in the article.
Back to top
Tools for creating an initrd
The cpio command
Using the cpio command, you can manipulate cpio files. Cpio is also a file format that is simply a concatenation of files with headers. The cpio file format permits both ASCII and binary files. For portability, use ASCII. For a reduced file size, use the binary version.
Let's now go back to the beginning to formally understand how the initrd image is constructed in the first place. For a traditional Linux system, the initrd image is created during the Linux build process. Numerous tools, such as mkinitrd, can be used to automatically build an initrd with the necessary libraries and modules for bridging to the real root file system. The mkinitrd utility is actually a shell script, so you can see exactly how it achieves its result. There's also the YAIRD (Yet Another Mkinitrd) utility, which permits customization of every aspect of the initrd construction.


1.2.2 Manually building a custom initial RAM disk

Because there is no hard drive in many embedded systems based on Linux, the initrd also serves as the permanent root file system. Listing 4 shows how to create an initrd image. I'm using a standard Linux desktop so you can follow along without an embedded target. Other than cross-compilation, the concepts (as they apply to initrd construction) are the same for an embedded target.

Listing 4. Utility (mkird) to create a custom initrd 
                
#!/bin/bash

# Housekeeping...
rm -f /tmp/ramdisk.img
rm -f /tmp/ramdisk.img.gz

# Ramdisk Constants
RDSIZE=4000
BLKSIZE=1024

# Create an empty ramdisk image
dd if=/dev/zero of=/tmp/ramdisk.img bs=$BLKSIZE count=$RDSIZE

# Make it an ext2 mountable file system
/sbin/mke2fs -F -m 0 -b $BLKSIZE /tmp/ramdisk.img $RDSIZE

# Mount it so that we can populate
mount /tmp/ramdisk.img /mnt/initrd -t ext2 -o loop=/dev/loop0

# Populate the filesystem (subdirectories)
mkdir /mnt/initrd/bin
mkdir /mnt/initrd/sys
mkdir /mnt/initrd/dev
mkdir /mnt/initrd/proc

# Grab busybox and create the symbolic links
pushd /mnt/initrd/bin
cp /usr/local/src/busybox-1.1.1/busybox .
ln -s busybox ash
ln -s busybox mount
ln -s busybox echo
ln -s busybox ls
ln -s busybox cat
ln -s busybox ps
ln -s busybox dmesg
ln -s busybox sysctl
popd

# Grab the necessary dev files
cp -a /dev/console /mnt/initrd/dev
cp -a /dev/ramdisk /mnt/initrd/dev
cp -a /dev/ram0 /mnt/initrd/dev
cp -a /dev/null /mnt/initrd/dev
cp -a /dev/tty1 /mnt/initrd/dev
cp -a /dev/tty2 /mnt/initrd/dev

# Equate sbin with bin
pushd /mnt/initrd
ln -s bin sbin
popd

# Create the init file
cat >> /mnt/initrd/linuxrc << EOF
#!/bin/ash
echo
echo "Simple initrd is active"
echo
mount -t proc /proc /proc
mount -t sysfs none /sys
/bin/ash --login
EOF

chmod +x /mnt/initrd/linuxrc

# Finish up...
umount /mnt/initrd
gzip -9 /tmp/ramdisk.img
cp /tmp/ramdisk.img.gz /boot/ramdisk.img.gz

1.2.3 An initrd Linux distribution
An interesting open source project that was designed to be a Linux distribution that fits within an initrd is Minimax. It's 32MB in size and uses BusyBox and uClibc for its ultra small size. Despite its small size, it's a 2.6 Linux kernel with a large array of useful tools.
To create an initrd, begin by creating an empty file, using /dev/zero (a stream of zeroes) as input writing to the ramdisk.img file. The resulting file is 4MB in size (4000 1K blocks). Then use the mke2fs command to create an ext2 (second extended) file system using the empty file. Now that this file is an ext2 file system, mount the file to /mnt/initrd using the loop device. At the mount point, you now have a directory that represents an ext2 file system that you can populate for your initrd. Much of the rest of the script provides this functionality.
The next step is creating the necessary subdirectories that make up your root file system: /bin, /sys, /dev, and /proc. Only a handful are needed (for example, no libraries are present), but they contain quite a bit of functionality.
Alternative to the ext2 file system
While ext2 is a common Linux file system format, there are alternatives that can reduce the size of the initrd image and the resulting mounted file systems. Examples include romfs (ROM file system), cramfs (compressed ROM file system), and squashfs (highly compressed read-only file system). If you need to transiently write data to the file system, ext2 works fine. Finally, the e2compr is an extension to the ext2 file system driver that supports online compression.
To make your root file system useful, use BusyBox. This utility is a single image that contains many individual utilities commonly found in Linux systems (such as ash, awk, sed, insmod, and so on). The advantage of BusyBox is that it packs many utilities into one while sharing their common elements, resulting in a much smaller image. This is ideal for embedded systems. Copy the BusyBox image from its source directory into your root in the /bin directory. A number of symbolic links are then created that all point to the BusyBox utility. BusyBox figures out which utility was invoked and performs that functionality. A small set of links are created in this directory to support your init script (with each command link pointing to BusyBox).
The next step is the creation of a small number of special device files. I copy these directly from my current /dev subdirectory, using the -a option (archive) to preserve their attributes.
The penultimate step is to generate the linuxrc file. After the kernel mounts the RAM disk, it searches for an init file to execute. If an init file is not found, the kernel invokes the linuxrc file as its startup script. You do the basic setup of the environment in this file, such as mounting the /proc file system. In addition to /proc, I also mount the /sys file system and emit a message to the console. Finally, I invoke ash (a Bourne Shell clone) so I can interact with the root file system. The linuxrc file is then made executable using chmod.
Finally, your root file system is complete. It's unmounted and then compressed using gzip. The resulting file (ramdisk.img.gz) is copied to the /boot subdirectory so it can be loaded via GNU GRUB.
To build the initial RAM disk, you simply invoke mkird, and the image is automatically created and copied to /boot.


* extracting commands

MY PROJECTS -*- mode: org; -*-

Linux   解压缩命令大全

linux下怎么解后缀名是gzip的文件？
1.以.a为扩展名的文件:
#tar xv file.a
2.以.z为扩展名的文件:
#uncompress file.Z
3.以.gz为扩展名的文件:
#gunzip file.gz
4.以.bz2为扩展名的文件:
#bunzip2 file.bz2
5.以.tar.Z为扩展名的文件:
#tar xvZf file.tar.Z
或 #compress -dc file.tar.Z | tar xvf -
6.以.tar.gz/.tgz为扩展名的文件:
#tar xvzf file.tar.gz
或 gzip -dc file.tar.gz | tar xvf -
7.以.tar.bz2为扩展名的文件:
#tar xvIf file.tar.bz2
或 bzip2 -dc file.tar.bz2 | xvf -
8.以.cpio.gz/.cgz为扩展名的文件:
#gzip -dc file.cgz | cpio -div
9.以.cpio/cpio为扩展名的文件:
#cpio -div file.cpio
或cpio -divc file.cpio
10.以.rpm为扩展名的文件安装:
#rpm -i file.rpm
11.以.rpm为扩展名的文件解压缩：
#rpm2cpio file.rpm | cpio -div
12.以.deb为扩展名的文件安装：
#dpkg -i file.deb
13.以.deb为扩展名的文件解压缩:
#dpkg-deb --fsys-tarfile file.deb | tar xvf - ar p
file.deb data.tar.gz | tar xvzf -
14.以.zip为扩展名的文件:
#unzip file.zip

在linux下解压Winzip格式的文件
　　要是装了jdk的话，可以用jar命令；还可以使用unzip命令。
直接解压.tar.gz文件
　　xxxx.tar.gz文件使用tar带zxvf参数，可以一次解压开。XXXX为文件名。 例如：
$tar zxvf xxxx.tar.gz
种压缩文件的解压（安装方法）

文件扩展名 解压（安装方法）

.a ar xv file.a
.Z uncompress file.Z
.gz gunzip file.gz
.bz2 bunzip2 file.bz2
.tar.Z tar xvZf file.tar.Z
compress -dc file.tar.Z | tar xvf -
.tar.gz/.tgz tar xvzf file.tar.gz
gzip -dc file.tar.gz | tar xvf -
.tar.bz2 tar xvIf file.tar.bz2
bzip2 -dc file.tar.bz2 | xvf -
.cpio.gz/.cgz gzip -dc file.cgz | cpio -div
.cpio/cpio cpio -div file.cpio
cpio -divc file.cpio
.rpm/install rpm -i file.rpm
.rpm/extract rpm2cpio file.rpm | cpio -div
.deb/install dpkg -i file.deb
.deb/exrtact dpkg-deb --fsys-tarfile file.deb | tar xvf -
ar p file.deb data.tar.gz | tar xvzf -
.zip unzip file.zip

bzip2 -d myfile.tar.bz2 | tar xvf

tar xvfz myfile.tar.bz2

x 是解压
v 是复杂输出
f 是指定文件
z gz格式

gzip
gzip[选项]要压缩（或解压缩）的文件名
-c将输出写到标准输出上，并保留原有文件。
-d将压缩文件压缩。
-l对每个压缩文件，显示下列字段：压缩文件的大小，未压缩文件的大小、压缩

比、未压缩文件的名字
-r递归式地查找指定目录并压缩或压缩其中的所有文件。
-t测试压缩文件是正完整。
-v对每一个压缩和解压缩的文件，显示其文件名和压缩比。
-num-用指定的数字调整压缩的速度。
举例：
把/usr目录并包括它的子目录在内的全部文件做一备份，备份文件名为usr.tar
tar cvf usr.tar /home
把/usr 目录并包括它的子目录在内的全部文件做一备份并进行压缩，备份文件名

是usr.tar.gz
tar czvf usr.tar.gz /usr
压缩一组文件，文件的后缀为tar.gz
#tar cvf back.tar /back/
#gzip -q back.tar
or
#tar cvfz back.tar.gz /back/
释放一个后缀为tar.gz的文件。
#tar zxvf back.tar.gz
#gzip back.tar.gz
#tar xvf back.tar 


* linux下代理设置

对于常用代理的，可以写入/etc/profile或者~/.bash_profile
/etc/profile.d/prox.sh
但有时不见得能起作用
export http-proxy = “192.168.0.123:8080″

subversion的代理服务器配置 ]

要配置subversion的代理服务器，需要修改$HOME/.subversion/servers文件，在此文件的[global]段加上：

http-proxy-host = 192.168.1.1
http-proxy-port = 8080
http-proxy-username = user
http-proxy-password = password

注意以上配置前面不要留有空格，否则使用svn时会出现如下错误

.subversion/servers:68: Option expected

附录，linux其它代理服务器设置参考

[ 通用代理服务器配置 ]

对于大多数Linux控制台程序，例如Debian或Ubuntu中的apt-get和aptitude命令、git命令、wget命令，这些程序都使用http_proxy和ftp_proxy环境变量来获取代理服务的配置。

方法是在你的~/.bashrc里加上类似下面的话：

export http_proxy=http://username:password@proxyserver:port/
export ftp_proxy=http://username:password@proxyserver:port/
如果你的代理服务器需要用户名和密码才能访问，需要填写上面的username和passwd部分，否则的话，省略这两部分。

例如，假设你的代理服务器为192.168.1.1，端口是8080，用户名为easwy，密码是123456，那么应该这样设置这两个环境变量：

export http_proxy=http://easwy:123456@192.168.1.1:8080
export ftp_proxy=http://easwy:123456@192.168.1.1:8080
这样配置之后，退出再登录一次，或者直接使用下面的命令source一下.bashrc：

source ~/.bashrc
现在，上述程序就可以通过代理服务器访问网络了。

[ yum的代理服务器配置 ]

如果想让CentOS中的yum可以通过代理服务器更新程序，则需要修改文件/etc/yum.conf，在此文件中加上：

proxy=http://easwy:123456@192.168.1.1:8080

现在使用yum就可以更新你的软件了。 

 

svn代理设置

修改~/.subversion/servers 文件

# http-proxy-host = 192.168.0.123
# http-proxy-port = 8080
rsync代理设置
exportRSYNC_PROXY="192.168.0.123:8080"
http/ftp代理设置
exporthttp_proxy="192.168.0.123:8080"exportFTP_PROXY="192.168.0.123:8080"exportHTTP_PROXY="192.168.0.123:8080"exportftp_proxy="192.168.0.123:8080"
git代理设置
git config --global http.proxy $http_proxy
python urllib2 代理设置
proxy = urllib2.ProxyHandler({'http': '127.0.0.1'}) opener = urllib2.build_opener(proxy)urllib2.install_opener(opener)urllib2.urlopen('http://www.google.com')

对于wget可以单独建立.wgetrc
http-proxy = “192.168.0.123:8080″
ftp-proxy = “192.168.0.123:8080″



apt-get
t /etc/apt/apt.conf在您的apt.conf文件中加入下面这行（根据你的实际情况替换yourproxyaddress和proxyport）。
Acquire::http::Proxy "http://yourproxyaddress:proxyport";保存apt.conf文件。


* linux内核Makefile分析

 
一般所有的makefile都是分目录的，模块和平级的目录对应，这样也就可以分模块编译了。

一般makefile有很多定义文件，脚本文件，这些其实都是分模块/目录编译的基础。
1.make 具体执行了哪些 命令
make -n 命令打印执行的命令，由于有时文件的生成有依赖关系，可以先执行一遍make后再佣-n，或与 w选项一起佣。
================================================================
set -e; echo '  CHK     include/generated/utsrelease.h'; mkdir -p include/generated/; 	if [ `echo -n "2.6.36-FriendlyARM" | wc -c ` -gt 64 ]; then echo '"2.6.36-FriendlyARM" exceeds 64 characters' >&2; exit 1; fi; (echo \#define UTS_RELEASE \"2.6.36-FriendlyARM\";) < include/config/kernel.release > include/generated/utsrelease.h.tmp; if [ -r include/generated/utsrelease.h ] && cmp -s include/generated/utsrelease.h include/generated/utsrelease.h.tmp; then rm -f include/generated/utsrelease.h.tmp; else echo '  UPD     include/generated/utsrelease.h'; mv -f include/generated/utsrelease.h.tmp include/generated/utsrelease.h; fi
mkdir -p .tmp_versions ; rm -f .tmp_versions/*
make -f scripts/Makefile.build obj=scripts/basic    //这是每个模块进入编译的命令，把obj传成不同的参数，就是不同的模块。
(cat /dev/null; ) > scripts/basic/modules.order
set -e;  echo '  HOSTCC  scripts/basic/docproc'; gcc -Wp,-MD,scripts/basic/.docproc.d -Wall -Wmissing-prototypes -Wstrict-prototypes -O2 -fomit-frame-pointer     -o scripts/basic/docproc scripts/basic/docproc.c  ; scripts/basic/fixdep scripts/basic/.docproc.d scripts/basic/docproc 'gcc -Wp,-MD,scripts/basic/.docproc.d -Wall -Wmissing-prototypes -Wstrict-prototypes -O2 -fomit-frame-pointer     -o scripts/basic/docproc scripts/basic/docproc.c  ' > scripts/basic/.docproc.tmp; rm -f scripts/basic/.docproc.d; mv -f scripts/basic/.docproc.tmp scripts/basic/.docproc.cmd

make -f scripts/Makefile.build obj=init      //这是每个模块进入编译的命令，把obj传成不同的参数，就是不同的模块。
echo '  CHK     include/generated/compile.h'
/bin/sh /home/zxx/friendandroid/linux-2.6.36-android/scripts/mkcompile_h include/generated/compile.h \
	"arm" "" "y" "arm-linux-gcc -Wall -Wundef -Wstrict-prototypes -Wno-trigraphs -fno-strict-aliasing -fno-common -Werror-implicit-function-declaration -Wno-format-security -fno-delete-null-pointer-checks -Os -marm -fno-dwarf2-cfi-asm -mabi=aapcs-linux -mno-thumb-interwork -funwind-tables  -D__LINUX_ARM_ARCH__=6 -march=armv6k -mtune=arm1136j-s  -msoft-float -Uarm -Wframe-larger-than=1024  -fno-stack-protector -fomit-frame-pointer -g -Wdeclaration-after-statement -Wno-pointer-sign -fno-strict-overflow -fconserve-stack"
==========================================================================

2. make的规则和变量
make -p
在编译每个模块时 都会打印一遍 所有的变量，内置的，环境的，自定义的，linux kernel这个右多达两千多行的变量定义，其实绝大多数是重复的哈。
每次都是先打印变量，再打印规则。
=================================
make-cmd = $(subst #,\#,$(subst $$,$$$$,$(call escsq,$(cmd_$(1)))))
# makefile (从'include/config/auto.conf'，行 624)

if_changed_dep = $(if $(strip $(any-prereq) $(arg-check) ), @set -e; $(echo-cmd) $(cmd_$(1)); scripts/basic/fixdep $(depfile) $@ '$(make-cmd)' > $(dot-target).tmp; rm -f $(depfile); mv -f $(dot-target).tmp $(dot-target).cmd)
# makefile (从'include/config/auto.conf'，行 622)
scripts/basic/fixdep
---------------------
// It is invoked as
 *
 *   fixdep <depfile> <target> <cmdline>
 *
 * and will read the dependency file <depfile>
 *
 * The transformed dependency snipped is written to stdout.
 *
 * It first generates a line
 *
 *   cmd_<target> = <cmdline>
 *
 * and then basically copies the .<target>.d file to stdout, in the
 * process filtering out the dependency on autoconf.h and adding
 * dependencies on include/config/my/option.h for every
 * CONFIG_MY_OPTION encountered in any of the prequisites.
--------------------------------------------------------------------------------------//把命令和依赖文件打印出来，实际又重新定向到*.cmd文件里 。


cmd_host-csingle = $(HOSTCC) $(hostc_flags) -o $@ $< $(HOST_LOADLIBES) $(HOSTLOADLIBES_$(@F))
# makefile (从'/home/zxx/friendandroid/linux-2.6.36-android/.config'，行 2001)

echo-cmd = $(if $($(quiet)cmd_$(1)), echo '  $(call escsq,$($(quiet)cmd_$(1)))$(echo-why)';)    //执行命令，并打印出来。
# makefile (从'Makefile'，行 326)

quiet_cmd_host-csingle = HOSTCC  $@
# makefile (从'include/config/auto.conf'，行 618)
...

scripts/basic/fixdep: scripts/basic/fixdep.c FORCE
#  对隐含规则的搜索尚未完成。
#  隐含/静态模式主干：“fixdep”
#  最近更新 2011-04-27 15:29:44.124470257
#  文件已经被更新。
#  更新成功。
# 自动
# @ := scripts/basic/fixdep
# 自动
# % := 
# 自动
# * := fixdep
# 自动
# + := scripts/basic/fixdep.c FORCE
# 自动
# | := 
# 自动
# < := scripts/basic/fixdep.c
# 自动
# ^ := scripts/basic/fixdep.c FORCE
# 自动
# ? := 
# 变量设置哈希表状态：
# 负载=8/32=25%, Rehash=0, 冲突=33/146=23%
#  要执行的命令 (从“scripts/Makefile.host”，行 118)：
	$(call if_changed_dep,host-csingle)              //if_changed_dep,是函数名，host-csingle是参数
==============================================
linux的内核编译会把每条执行的命令记录到一个相应的.cmd的文件里，这样你就可以清晰地看到所有文件是怎么生成的了。注意这种方式，很好用。
在Makefile的-p每次还是会打印变量的名字，很麻烦。


这样对整个编译过程就可以一目了然了。其实佣makefile自身的-n，-p只是辅助调试手段  make -n |tee makelog-n 
分析makelog-n可以找到命令。
但是-p的rule还是需要从变量中来，所以fixdep和echo-cmd才会很清晰地看到，以后要想调试makefile可以借鉴，但不一定能佣。

总之，linux内核编译是从scripts/basic里 开始，先编译编译的工具，比如fixdep，然后开始分模块编译。






PRIVATE_ALL_SHARED_LIBRARIES := out/target/product/generic/obj/lib/libbinder.so out/target/product/generic/obj/lib/libmedia.so out/target/product/generic/obj/lib/libutils.so out/target/product/generic/obj/lib/libui.so out/target/product/generic/obj/lib/liblog.so out/target/product/generic/obj/lib/libcutils.so out/target/product/generic/obj/lib/libsurfaceflinger_client.so out/target/product/generic/obj/lib/libcamera_client.so out/target/product/generic/obj/lib/libc.so out/target/product/generic/obj/lib/libstdc++.so out/target/product/generic/obj/lib/libm.so
* linux常用命令
** find
find ./
this will list all the files and directories of the current directory
find ./
-------------------------------------------------------------------
./README.md
./doc
./doc/shell.txt
./doc/misc.txt
-------------------------------------------------------------------
*** -path
-path means the file/dir name, -path [pattern]

[admin1@TeamCI-136 vs]$ find ./ -path "./plugin/*" 
./plugin/shell.vim
./plugin/xolox
./plugin/xolox/misc.vim
###this mean only print the files which begin with plugin
[admin1@TeamCI-136 vs]$ find ./ -path "./plugin"
./plugin
[admin1@TeamCI-136 vs]$ find ./ -path "./plugin*"
./plugin
./plugin/shell.vim
./plugin/xolox
./plugin/xolox/misc.vim

find will process diretory first then it's contents

*** -depth
       -depth Process each directory’s contents before the directory itself.
[admin1@TeamCI-136 vs]$ find  ./  -depth  -path "./plugin*"
./plugin/shell.vim
./plugin/xolox/misc.vim
./plugin/xolox
./plugin
[admin1@TeamCI-136 vs]$
用depth选项

在使用find命令时，可能希望先匹配所有的文件，再在子目录中查找。使用depth选项就可以使find命令这样做。这样做的一个原因就是，当在使用find命令向磁带上备份文件系统时，希望首先备份所有的文件，其次再备份子目录中的文件。
在下面的例子中， find命令从文件系统的根目录开始，查找一个名为CON.FILE的文件。
它将首先匹配所有的文件然后再进入子目录中查找。
$ find / -name "CON.FILE" -depth -print


*** -prune
-prune If -depth is not given, true; if the file is a directory, do not descend into it.
       If -depth is given, false; no effect.
[admin1@TeamCI-136 vs]$ find ./ -path "./plugin" -prune
./plugin
##whe prune work with path mean this directory not descend into it, but the directory itself will be printed.

*** -not
-not: meaning that filter out 
\( \)  a group  -not after a group 
##if you want to eliminate all the directory, you need, all other files/dir listed othe than ./plugin begining with:
[admin1@TeamCI-136 vs]$ find ./ -not  \( -path "./plugin" -prune \)

## this will be the same effect, but different effeciency. this through [PATTERN] to filterout ./plugin beginning thing, but former one is more effecient, for the dir not be descend into, but this one, this dir has desend into it, but filter out it
[admin1@TeamCI-136 vs]$ find ./ -not  \( -path "./plugin*"  \)


*** -a
-a 是并且 ,-a也可以省略
find ./ -name bc  -a -type f
## find a file named bc not dirctory named bd

*** -o
[admin1@TeamCI-136 vs]$ find ./  -path "./plugin"  -prune -o  -print
-------------------------------
if -path "./plugin"  then
 -prune
else
 -print
--------------------------------

**** multiple path filter
## below two are identical
[admin1@TeamCI-136 vs]$ find ./ \( -path ./plugin -o -path ./autoload \)  -prune  -o  -print
[admin1@TeamCI-136 vs]$ find ./ -path ./plugin  -prune  -o -path ./autoload  -prune  -o  -print

*** -name
zxx@zxx-desktop:/tmp/test$ find . -name *.txt
./a1.txt
zxx@zxx-desktop:/tmp/test$ find . -name "*.txt"
./a1.txt
./ta/tc/c1.txt
./ta/b1.txt

*** -size
##为了查找系统中所有文件长度为0的普通文件，并列出它们的完整路径；
$ find / -type f -size 0 -exec ls -l {  } \;

cut -d: -f1 &lt;   /etc/passwd    | sort | xargs  find echo
紧凑排列参数

*** -exec
-print 用法：一般情况下，find都会打印出查找到的文件，但是在用-exec处理之后，就无法
打印，这时需要家-print
[admin1@TeamCI-136 vs]$ find ./ -name "*.vim" -exec grep "Default" {} \;
" Default key mappings. {{{1

[admin1@TeamCI-136 vs]$ find ./ -name "*.vim" -exec grep "Default" {} \;
./plugin/shell.vim
" Default key mappings. {{{1

*** -regex
in default * will be interpreted as glob one by shell, if you want to use it in regular expression:
[lily@willow:/tmp$ find  -type f -regex "./te.*" -print -exec  grep  "ab" {} \;
./test.c 
ab cdef

*** -iregex
// 忽略大小写查找文件名
lily@willow:/tmp$ find . -type f -iregex "./TE.*" -printf "%p \t"
./test ./test.c 


*** -mtime
查找/var/logs目录中更改时间在7日以前的普通文件，并在删除之前询问它们；
$ find /var/logs  -type f -mtime +7 -ok rm {} \;

mtime +_n       修改时间在距现在 （+_n天） 以内的。  
                               -n 表示  小于n天
                                 n 表示 等于n天 ()  n 是精确匹配，慎用，不确定佣+-
                              +n 表示 多于n天
所以通过+_n这三个数可以表示一个时间段内修改的文件


                                 |
---------------------------------|---------------------------------------------->
           ...       n+1         |n          .....       3       2      1      0 now
|                                |                                              |
|                                |                                              |
|-------  -n  -------------------|  -----------+n---------------------------    |
                                 n
to test that
touch -d "20120412 10:30" tf

*** -atime, -ctime, 
ls -l  显示 的是 modify时间，  ls -al 显示 change时间
mtime  ls -l  最近修改文件内容的时间
atime  ls -lu 最近访问文件的时间
ctime  ls -lc 最近文件有所改变的状态 ,如文件修改,属性\属主 改变 ,节点 ,链接变化等 ,应该是不拘泥只是时间前后的改变

----------------------------------------------------
$ stat log_rel-8_dev1.html
  File: ‘log_rel-8_dev1.html’
    Size: 16824118        Blocks: 16432      IO Block: 65536  regular file
    Device: 84f83dd6h/2230861270d   Inode: 4785074604163869  Links: 1
    Access: (0644/-rw-r--r--)  Uid: (1423898/   glili)   Gid: (10513/Domain Users)
    Access: 2015-01-01 03:23:00.000000000 +0800
    Modify: 2015-02-27 04:57:02.000000000 +0800
    Change: 2015-02-28 11:15:00.618086800 +0800
     Birth: 2015-02-28 11:01:24.148627500 +0800

 $ ls -l log_rel-8_dev1.html
     -rw-r--r--+ 1 glili Domain Users 16824118 Feb 27 04:57 log_rel-8_dev1.html

 $ ls -lu log_rel-8_dev1.html
     -rw-r--r--+ 1 glili Domain Users 16824118 Jan  1 03:23 log_rel-8_dev1.html

 $ ls -lc log_rel-8_dev1.html
     -rw-r--r--+ 1 glili Domain Users 16824118 Feb 28 11:15 log_rel-8_dev1.html
---------------------------------------------------------------
Modify和 Change 区别 ： 一般改变文件的 内容后 这两个都要 变化
如果 改变文件的模式，如chmod，则只改变 文件的Change时间
stat文件，并不 改变文件 的访问时间

###change the file's mtime (Modification time), use
touch -m -d '1 Jan 2006 12:34' test.txt

### change the file's atime (Last access time), use
touch -a -d '1 Jan 2006 12:34' test.txt

** -mmin -amin -cmin
modify access change 
精确 到 分钟


*** -newermt
比如要查找2-25日修改过的文件，用命令：
find ./ -newermt 2011-02-24 ! -newermt 2011-02-26
touch -t 03272001 filename 

*** -ok
-ok is the same effect as -exec except that it will ask you to confirm before the command executed
find命令将删除当目录中访问时间在7日以来、含有数字后缀的admin.log文件。
该命令只检查三位数字，所以相应文件的后缀不要超过999。先建几个admin.log*的文件 ，才能使用下面这个命令

$ find . -name "admin.log[0-9][0-9][0-9]" -atime -7  -ok rm {} \;
< rm ... ./admin.log001 ? n
< rm ... ./admin.log002 ? n
< rm ... ./admin.log042 ? y 
< rm ... ./admin.log942 ? n<strikethrough>

*** -group
查找系统中所有属于root组的文件；
$find . -group root -exec ls -l {  } \;
-rw-r--r--    1 root     root          595 10月 31 01:09 ./fie1


*** -perm
-perm mode:文件许可正好符合mode
-perm +mode:文件许可部分符合mode
-perm -mode: 文件许可完全符合mode

** grep
-include=PATTERN     Recurse in directories only searching file matching PATTERN.
--exclude=PATTERN     Recurse in directories skip file matching PATTERN.
these are only pattern, and you can't use directory name or file name for it.
 	
	Use the shell globbing syntax:
	grep pattern -r --include=\*.{cpp,h} rootdir
	grep pattern -r --exclude=\*.{cpp,h} rootdir

避免出现permission denied
find / -name access_log 2&gt;/dev/null


* convertion between hexstring and ascii
** convert hexstring to ascii
xxd -make a hexdump or do the reverse
source file
---File contents:

00000000  0054 0065 0073 0074 0020 0054 0065 0073
00000008  0074 0020 0054 0065 0073 0074 0020 0054
00000016  0065 0073 0074 0020 0054 0065 0073 0074
00000024  0020 0054 0065 0073 0074 0020 0054 0065
-------------
[guolili@cougar project]$ cut -c 11- ~/ttss |xxd -r -p
IPR/1.0;UdpTcpInd;protocol:tcp;indId:messageInd;localIpAddrAndPort:{10.101.101.181@0};sutIpAddrAndPort:{10.255.31.58@50000};[guolili@cougar project]$
--------------

od---- is objdump tools to dump hexstring of the charstring

[root@TTCN9 test]# echo "AB" |od -w1 -v -t x1a
0000000 41
          A
0000001 42
          B
0000002 0a
         nl
0000003
[root@TTCN9 test]# echo "AB" |od -w4 -v -t x1a
0000000 41 42 0a
          A   B  nl
0000003
[root@TTCN9 test]# echo "AB" |od -w4 -v -t x2a
0000000 4241 000a
          A   B  nl nul


hexdump -- another tool to dump charstring to hex
[root@TTCN9 test]# echo Aa |hexdump
0000000 6141 000a
0000003




** convert ascii to hexstring
xxd : 

oot@TTCN9 test]# echo "AB"|xxd -g 1 |tee file
0000000: 41 42 0a                                         AB.

[root@a]# xxd -r file
AB

*convert hex to ascii line by line
[root@TTCN9 test]# head /tmp/ff |gawk '{printf "%s  |", $0; for (f=2; f<=16; f++) { c = strtonum("0x" $f); if (c >= 32 && c <= 126) printf "%c",c; else printf "."}; printf "|\n"}'
     00003570: 4e 6f 74 20 6f 70 74 69 6d 69 73 65 64 20 66 6f  |Not optimised f|
     00003580: 72 20 73 69 67 6e 61 6c 6c 69 6e 67 20 74 72 61  |r signalling tr|
     00003590: 66 66 69 63 3c 2f 6e 65 67 6f 74 69 61 74 65 64  |ffic</negotiate|
     000035a0: 51 6f 73 53 69 67 6e 61 6c 6c 69 6e 67 49 6e 64  |QosSignallingIn|
     000035b0: 69 63 61 74 69 6f 6e 3e 0a 3c 6e 65 67 6f 74 69  |ication>.<negot|
     000035c0: 61 74 65 64 51 6f 73 45 78 74 65 6e 64 65 64 4d  |atedQosExtended|
     000035d0: 61 78 42 69 74 52 61 74 65 46 6f 72 44 6f 77 6e  |axBitRateForDow|
     000035e0: 6c 69 6e 6b 3e 45 6d 70 74 79 3c 2f 6e 65 67 6f  |link>Empty</neg|
     000035f0: 74 69 61 74 65 64 51 6f 73 45 78 74 65 6e 64 65  |tiatedQosExtend|
     00003600: 64 4d 61 78 42 69 74 52 61 74 65 46 6f 72 44 6f  |dMaxBitRateForD|

[root@TTCN9 test]# head /tmp/ff
00003570: 4e 6f 74 20 6f 70 74 69 6d 69 73 65 64 20 66 6f
00003580: 72 20 73 69 67 6e 61 6c 6c 69 6e 67 20 74 72 61
00003590: 66 66 69 63 3c 2f 6e 65 67 6f 74 69 61 74 65 64
000035a0: 51 6f 73 53 69 67 6e 61 6c 6c 69 6e 67 49 6e 64
000035b0: 69 63 61 74 69 6f 6e 3e 0a 3c 6e 65 67 6f 74 69
000035c0: 61 74 65 64 51 6f 73 45 78 74 65 6e 64 65 64 4d
000035d0: 61 78 42 69 74 52 61 74 65 46 6f 72 44 6f 77 6e
000035e0: 6c 69 6e 6b 3e 45 6d 70 74 79 3c 2f 6e 65 67 6f
000035f0: 74 69 61 74 65 64 51 6f 73 45 78 74 65 6e 64 65
00003600: 64 4d 61 78 42 69 74 52 61 74 65 46 6f 72 44 6f







History命令主要用于显示历史指令记录内容, 下达历史纪录中的指令 。

1>History命令语法：

[test@linux]# history [n]
[test@linux]# history [-c]
[test@linux]# history [-raw] histfiles
参数：
n   ：数字,要列出最近的 n 笔命令列表
-c  ：将目前的shell中的所有 history 内容全部消除
-a  ：将目前新增的history 指令新增入 histfiles 中，若没有加 histfiles ，
则预设写入   ~/.bash_history   
etr  ：将 histfiles 的内容读到目前这个 file replace with - in shell 的 history 记忆中
-w  ：将目前的 history 记忆内容写入 histfiles

Linux系统当你在shell(控制台)中输入并执行命令时，shell会自动把你的命令记录到历史列表中，一般保存在用户目录下的.bash_history文件中。默认保存1000条，你也可以更改这个值。

如果你键入 history, history会向你显示你所使用的前1000个历史命令，并且给它们编了号，你会看到一个用数字编号的列表快速从屏幕上卷过。你可能不需要查看1000个命令中的所有项目, 当然你也可以加入数字来列出最近的 n 笔命令列表。

linux中history命令不仅仅让我们可以查询历史命令而已. 我们还可以利用相关的功能来帮我们执行命令。

2>运行特定的历史命令

history会列出bash保存的所有历史命令，并且给它们编了号，我们可以使用“叹号接编号”的方式运行特定的历史命令.

语法说明:
[test@linux]# [!number]  [!command] [!!]
参数说明：
number   ：第几个指令的意思；
command  ：指令的开头几个字母
!        ：上一个指令的意思！

3>History命令实战

列出所有的历史记录：
[test@linux] # history

只列出最近10条记录：
[test@linux] # history 10 (注,history和10中间有空格)

使用命令记录号码执行命令,执行历史清单中的第99条命令
[test@linux] #!99 (!和99中间没有空格)

重复执行上一个命令
[test@linux] #!!

执行最后一次以rpm开头的命令(!?  ?代表的是字符串,这个String可以随便输，Shell会从最后一条历史命令向前搜索，最先匹配的一条命令将会得到执行。)
[test@linux] #!rpm

逐屏列出所有的历史记录：
[test@linux]# history | more

立即清空history当前所有历史命令的记录
[test@linux] #history -c

除了使用history命令,在 file replace with - in shell 或 GUI 终端提示下，你也可以使用上下方向键来翻阅命令历史(向下箭头会向前翻阅)，直到你找到所需命令为止。这可以让我们很方便地编辑前面的某一条命令，而不用重复输入类似的命令。

History命令的用途确实很大！但需要小心安全的问题!尤其是 root 的历史纪录档案，这是黑客们的最爱！因为不小心的 root 会将很多的重要资料在执行的过程中会被纪录在   ~/.bash_history    当中，如果这个档案被解析的话，后果不堪设想！
** add the time stamp of the history command
HISTTIMEFORMAT="%Y%m%d-%H%M%S: "
exoport HISTTIMEFORMAT
--------------

shell参数命令
  
 
1.!! 前一条命令 
 
2.!:0 不带参数的前一条命令名 
 
 
 
3.!^ 前一条命令的第一个参数 
 
4.!:n 前一条命令的第n个参数 
 
 
 
5.!$ 前一条命令的最后一个参数 
 
6.!* 前一条命令的所有参数，命令名除外 
 
 
 
7.!n 第n条命令 
 
8.!-n 倒数第n条命令 
 
 
 
9.!str 最近一条以str开头的命令 
 
10.!?str 最近一条包含str的命令 
 
 
 
11.^a^b 将上一条命令名中的a替换为b 
 
 
 
12.!:gs/a/b 将上一条命令的所有a替换为b（包含命令名和参数）


重定：
#ls /dev &amp;>filename   标准输出和错误输出到filename
#ls /dev        2>errorlog  错误输出到 errorlog  或/dev/null
#ls /dev &gt;stdoutfile      


du -sk ./* |sort -g    //统计当前目录下各个目录或文件的大小并按数字大小排列
ls -al | sort -k  5    //统计输出按第五列排序
find ./ -type f -print0 |xargs  -0  grep "Template"   //使用于文件或目录名含空格

Linux  命令xargs
------------------------------
xargs  调试用法
cat filename |xargs -p echo
li@ubuntu:~$ cat ts
ab
cd
ef
li@ubuntu:~$ cat ts |xargs echo
ab cd ef
li@ubuntu:~$ cat ts |xargs -p echo
echo ab cd ef ?...y
ab cd ef
li@ubuntu:~$ 
//这里xargs是把所有的参数读入一行以空格分割的，最后作为参数传入命令行
--------------------------
li@ubuntu:~$ cat ts |xargs -I '{}' echo '{}'
ab
cd
ef
li@ubuntu:~$ cat ts |xargs -p -I '{}' echo '{}'
echo ab ?...y
echo cd ?...ab
y
echo ef ?...cd
y
ef
li@ubuntu:~$ 
//这里可以让xargs一条一条地执行命令
--------------------------------------------
-I 相当于-L 1
   -L max-lines
       Use at most max-lines nonblank input  lines  per  command  line.
-------------------------------------------------------------------------    @ubuntu:~$ cat ts |xargs  -i sh -c 'file="{}"; echo $file'
ab
cd
ef
li@ubuntu:~$ cat ts |rgs -p -i sh -c 'file="{}"; echo $file'
sh -c file="ab"; echo $file ?...y
sh -c file="cd"; echo $file ?...ab
y
sh -c file="ef"; echo $file ?...cd
y
ef
//需要执行多条指令的情况，用sh -c ''
---------------------------
find ./ -type f |xargs -i sh -c 'f="{}"; file $f|grep text|grep exec >/dev/null;  [ "0" -eq "$?"  ] && echo $f '
//查找当前文件夹下可执行的文本文件
----------------- 
cat list.txt |xargc wget     相当于wget -c `cat list.txt`
调用wget一次，传递一串参数给wget

cat list.txt | while read line; do wget $line; done   实际要循环调用仍然需要shell循环，如果是find命令的输出结果应该用-exec
保证每个文件都会调用一次命令

如果list.txt一行里有空白，引号等特殊字符则需要告诉xargs只用 \n作为定界符，而不是空白和换行都做定界符。

cat list.txt|xargs  find –delimiter=”\n” wget -c


grep命令详解
grep默认要查找二进制文件。可用命令--binary-files=without-match
linux下grep命令用法实例教程
2011-02-26 14:49
linux下grep命令用法实例教程   http://blog.51yip.com/linux/1008.html   

一，grep命令有什么用

个人觉得grep命令就是一个对文本或输出进行匹配并控制输出的一个工具,看一下下面的参数，部分翻译了，有不对的地方，还请指正
grep --help 
匹配模式选择: 
-E, --extended-regexp 扩展正则表达式egrep 
-F, --fixed-strings 一个换行符分隔的字符串的集合fgrep 
-G, --basic-regexp 基本正则 
-P, --perl-regexp 调用的perl正则 
-e, --regexp=PATTERN 后面根正则模式，默认无 
-f, --file=FILE 从文件中获得匹配模式 
-i, --ignore-case 不区分大小写 
-w, --word-regexp 匹配整个单词 
-x, --line-regexp 匹配整行 
-z, --null-data a data line ends in 0 byte, not newline 

杂项: 
-s, --no-messages 不显示错误信息 
-v, --invert-match 显示不匹配的行 
-V, --version 显示版本号 
--help 显示帮助信息 
--mmap use memory-mapped input if possible 

输入控制: 
-m, --max-count=NUM 匹配的最大数 
-b, --byte-offset 打印匹配行前面打印该行所在的块号码。 
-n, --line-number 显示的加上匹配所在的行号 
--line-buffered 刷新输出每一行 
-H, --with-filename 当搜索多个文件时，显示匹配文件名前缀 
-h, --no-filename 当搜索多个文件时，不显示匹配文件名前缀 
--label=LABEL print LABEL as filename for standard input 
-o, --only-matching show only the part of a line matching PATTERN 
-q, --quiet, --silent 不显示任何东西 
--binary-files=TYPE assume that binary files are TYPE 
TYPE is 'binary', 'text', or 'without-match' 
-a, --text 匹配二进制的东西 
-I 不匹配二进制的东西 
-d, --directories=ACTION 目录操作，读取，递归，跳过 
ACTION is 'read', 'recurse', or 'skip' 
-D, --devices=ACTION 设置对设备，FIFO,管道的操作，读取，跳过 
ACTION is 'read' or 'skip' 
-R, -r, --recursive 递归调用 
--include=PATTERN files that match PATTERN will be examined 
--exclude=PATTERN files that match PATTERN will be skipped. 
--exclude-from=FILE files that match PATTERN in FILE will be skipped. 
-L, --files-without-match 匹配多个文件时，显示不匹配的文件名 
-l, --files-with-matches 匹配多个文件时，显示匹配的文件名 
-c, --count 显示匹配了多少次 
-Z, --null print 0 byte after FILE name 

文件控制: 
-B, --before-context=NUM 打印匹配本身以及前面的几个行由NUM控制 
-A, --after-context=NUM 打印匹配本身以及随后的几个行由NUM控制 
-C, --context=NUM 打印匹配本身以及随后，前面的几个行由NUM控制 
-NUM 根-C的用法一样的 
--color[=WHEN], 
--colour[=WHEN] use markers to distinguish the matching string 
WHEN may be `always', `never' or `auto'. 
-U, --binary do not strip CR characters at EOL (MSDOS) 
-u, --unix-byte-offsets report offsets as if CRs were not there (MSDOS)

二，准备测试文件test

root:x:0:0:root:/root:/bin/bash 
bin:x:1:1:bin:/bin:/bin/false,aaa,bbbb,cccc,aaaaaa 
DADddd:x:2:2:daemon:/sbin:/bin/false 
mail:x:8:12:mail:/var/spool/mail:/bin/false 
ftp:x:14:11:ftp:/home/ftp:/bin/false 
&amp;nobody:$:99:99:nobody:/:/bin/false 
zhangy:x:1000:100:,,,:/home/zhangy:/bin/bash 
http:x:33:33::/srv/http:/bin/false 
dbus:x:81:81:System message bus:/:/bin/false 
hal:x:82:82:HAL daemon:/:/bin/false 
mysql:x:89:89::/var/lib/mysql:/bin/false 
aaa:x:1001:1001::/home/aaa:/bin/bash 
ba:x:1002:1002::/home/zhangy:/bin/bash 
test:x:1003:1003::/home/test:/bin/bash 
@zhangying:*:1004:1004::/home/test:/bin/bash 
policykit:x:102:1005:Po

这个测试文件，根介绍sed和awk命令时用的一样的，是个密码文件。

三，应用举例

 [root@krlcgcms01 test]# grep root test 
root:x:0:0:root:/root:/bin/bash 

匹配含有root的行
查看复制打印?
[root@krlcgcms01 test]# cat test |grep '^\(root\|zhang\)' 
root:x:0:0:root:/root:/bin/bash 
zhangy:x:1000:100:,,,:/home/zhangy:/bin/bash 

匹配以root开头或者以zhang开头的行，注意反斜杠
查看复制打印?
[root@krlcgcms01 test]# cat test |grep -e '^\(root\|zhang\)' 
root:x:0:0:root:/root:/bin/bash 
zhangy:x:1000:100:,,,:/home/zhangy:/bin/bash 

匹配以root开头或者以zhang开头的行，注意反斜杠,根上面一个例子一样，-e默认是省去的
查看复制打印?
[root@krlcgcms01 test]# echo 'zhangying' |grep '^zhang[a-z]*$' 
zhangying 

匹配以zhang开头，只含有字母
查看复制打印?
[root@krlcgcms01 test]# cat test |grep -E '^bin' 
bin:x:1:1:bin:/bin:/bin/false,aaa,bbbb,cccc,aaaaaa 

匹配以bin开头的行,用的egrep，在这里可以换成-F,-G
[root@krlcgcms01 test]# cat test|grep -n zhangy 
7:zhangy:x:1000:100:,,,:/home/zhangy:/bin/bash 
13:ba:x:1002:1002::/home/zhangy:/bin/bash 
15:@zhangying:*:1004:1004::/home/test:/bin/bash 

在匹配的行前面加上该行在文件中，或者输出中所在的行号
[root@krlcgcms01 test]# cat test|grep -nv bin 
16:policykit:x:102:1005:Po 

不匹配以bin开头的行,并显示行号
[root@krlcgcms01 test]# cat test|grep -c zhang 
3 

显示匹配的个数，不显示内容
[root@krlcgcms01 test]# grep system test 
[root@krlcgcms01 test]# grep -ni system test 
9:dbus:x:81:81:System message bus:/:/bin/false 

匹配system，没有加-i没有匹配到东西。
[root@krlcgcms01 test]# cat test|grep -w zhan 
[root@krlcgcms01 test]# cat test|grep -w zhangy 
zhangy:x:1000:100:,,,:/home/zhangy:/bin/bash 
ba:x:1002:1002::/home/zhangy:/bin/bash 

匹配zhan没有匹配到东西，匹配zhangy能匹配到，因为在test文件中，有zhangy这个单词
查看复制打印?
[root@krlcgcms01 test]# echo "aaaaaa" |grep -x aaa 
[root@krlcgcms01 test]# echo "aaaa" |grep -x aaaa 
aaaa 

在这里-x后面东西，和输出中的整行相同时，才会输出
[root@krlcgcms01 test]# cat test |grep -m 1 zhang 
zhangy:x:1000:100:,,,:/home/zhangy:/bin/bash 

最多只匹配一次，如果把-m 1去掉的话，会有三个
[apacheuser@krlcgcms01 test]$ cat test |grep -b zha 
241:zhangy:x:1000:100:,,,:/home/zhangy:/bin/bash 
480:ba:x:1002:1002::/home/zhangy:/bin/bash 
558:@zhangying:*:1004:1004::/home/test:/bin/bash 

匹配行的前面显示块号，这个块号是干什么的，不知道，有谁知道可否告诉我一下
查看复制打印?
[apacheuser@krlcgcms01 test]$ grep -H 'root' test test2 testbak 
test:root:x:0:0:root:/root:/bin/bash 
test2:root 
testbak:root:x:0:0:root:/root:/bin/bash 

多文件匹配时，在匹配的行前面加上文件名
查看复制打印?
[apacheuser@krlcgcms01 test]$ grep -h 'root' test test2 testbak 
root:x:0:0:root:/root:/bin/bash 
root 
root:x:0:0:root:/root:/bin/bash 

多文件匹配时，在匹配的行前面不加上文件名
查看复制打印?
[apacheuser@krlcgcms01 test]$ grep -l 'root' test test2 testbak DAta 
test 
test2 
testbak 

多文件匹配时，显示匹配文件的文件名
查看复制打印?
[apacheuser@krlcgcms01 test]$ grep -L 'root' test test2 testbak DAta 
DAta 

多文件匹配时，在匹配的行前面不加上文件名
查看复制打印?
[apacheuser@krlcgcms01 test]$ grep 'root' test 
root:x:0:0:root:/root:/bin/bash 
[apacheuser@krlcgcms01 test]$ grep -o 'root' test 
root 
root 
root 

没有-o时，有一行匹配，这一行里面有3个root，加上-o后，这个3个root就出来了
[apacheuser@krlcgcms01 test]$ grep -V 
grep (GNU grep) 2.5.1 

Copyright 1988, 1992-1999, 2000, 2001 Free Software Foundation, Inc. 

显示版本
查看复制打印?
[apacheuser@krlcgcms01 test]$ grep -q 'root' test 

不显示任何内容
[root@krlcgcms01 test]# grep test -R   /tmp/test/mytest    
  /tmp/test/mytest/test:test:x:1003:1003::/home/test:/bin/bash    
  /tmp/test/mytest/test:@zhangying:*:1004:1004::/home/test:/bin/bash    

递归显示匹配的内容，在test目录下面建个mytest目录，copy test目录下面的test文件到mytest下面，能看到上面的结果
查看复制打印?
[root@krlcgcms01 test]# cat test |grep -A 3 root 
root:x:0:0:root:/root:/bin/bash 
bin:x:1:1:bin:/bin:/bin/false,aaa,bbbb,cccc,aaaaaa 
daemon:x:2:2:daemon:/sbin:/bin/false 
mail:x:8:12:mail:/var/spool/mail:/bin/false 

显示匹配root后面的3行
查看复制打印?
[root@krlcgcms01 test]# cat test |grep -B 2 ftp 
daemon:x:2:2:daemon:/sbin:/bin/false 
mail:x:8:12:mail:/var/spool/mail:/bin/false 
ftp:x:14:11:ftp:/home/ftp:/bin/false 

显示匹配ftp前面的2行
查看复制打印?
[root@krlcgcms01 test]# cat test |grep -C 2 ftp 
daemon:x:2:2:daemon:/sbin:/bin/false 
mail:x:8:12:mail:/var/spool/mail:/bin/false 
ftp:x:14:11:ftp:/home/ftp:/bin/false 
&amp;nobody:$:99:99:nobody:/:/bin/false 
zhangy:x:1000:100:,,,:/home/zhangy:/bin/bash 

显示匹配ftp前面的2行，后面的2行，以及本身
查看复制打印?
[root@krlcgcms01 test]# cat test |grep -2 ftp 
daemon:x:2:2:daemon:/sbin:/bin/false 
mail:x:8:12:mail:/var/spool/mail:/bin/false 
ftp:x:14:11:ftp:/home/ftp:/bin/false 
&amp;nobody:$:99:99:nobody:/:/bin/false 
zhangy:x:1000:100:,,,:/home/zhangy:/bin/bash 

Linux命令：<bold>modprobe</bold>
　　功能说明：<highlight>自动处理可载入模块。</highlight>
　　语　法：modprobe [-acdlrtvV][--help][模块文件][符号名称 = 符号值]
　　补充说明：modprobe可载入指定的个别模块，或是载入一组相依的模块。modprobe会根据depmod所产生的相依关系，决定要载入哪些模块。若在载入过程中发生错误，在modprobe会卸载整组的模块。
内容
　　1、modprobe 命令是根据depmod -a的输出/lib/modules/version/modules.dep来加载全部的所需要模块。
　　2、删除模块的命令是：modprobe -r filename
　　3、系统启动后，正常工作的模块都在/proc/modules文件中列出。使用lsmod命今也可显示相同内容。
　　4、在内核中有一个“Automatic kernel module loading"功能被编译到了内核中。当用户尝试打开某类型的文件时，内核会根据需要尝试加载相应的模块。/etc/modules.conf或   /etc/modprobe.conf文件是一个自动处理内核模块的控制文件   。

file replace with - in shell set -e
Make a script exit immediately after any failed command with set -e

Exit immediately if a simple command (see file replace with - in shell GRAMMAR above) exits with a non-zero status


 查看磁盘空间和文件夹大小
查看文件夹的大小
   du -sh dirname
   取得文件夹大小
   du --max-depth=1 dirname
   查看当前文件夹下各个文件夹的大小
   du -a  取得每一个文件大小信息
查看磁盘空间的大小
 df
查看当前系统状况
top

source和直接执行脚本的区别
source在当前bash环境下执行命令，而scripts是启动一个子shell来执行命令。这样如果把设置环境变量（或alias等等）的命令写进scripts中，就只会影响子shell,无法改变当前的BASH,所以通过文件（命令列）设置环境变量时，要用source 命令。 
用户登录到Linux系统后，系统将启动一个用户shell。在这个shell中，可以使用shell命令或声明变量，也可以创建并运行shell脚本程序。运行shell脚本程序时，系统将创建一个子shell。此时，系统中将有两个shell，一个是登录时系统启动的shell，另一个是系统为运行脚本程序创建的shell。当一个脚本程序运行完毕，它的脚本shell将终止，可以返回到执行该脚本之前的shell。从这种意义上来说，用户可以有许多 shell，每个shell都是由某个shell（称为父shell）派生的。
      在子 shell中定义的变量只在该子shell内有效。如果在一个shell脚本程序中定义了一个变量，当该脚本程序运行时，这个定义的变量只是该脚本程序内的一个局部变量，其他的shell不能引用它，要使某个变量的值可以在其他shell中被改变，可以使用export命令对已定义的变量进行输出。 export命令将使系统在创建每一个新的shell时定义这个变量的一个拷贝。这个过程称之为变量输出。

export 变量后，在这个shell里执行的子shell程序都将共享到设置这个变量的值
------------------------
lily@willow:~$cat ~/testAA.sh
#!/bin/sh
echo $AA
echo $LANG
lily@willow:~$ AA=5
lily@willow:~$ echo $AA
5
lily@willow~$ ~/testAA.sh

zh_CN.UTF-8
lily@willow:~$ export AA=9
lily@willow:~$ echo $AA
9
lily@willow:~$ ~/testAA.sh
9
zh_CN.UTF-8
---------------------------

##########################
source script.sh (. script.sh)
/bin/sh script.sh(./script.sh)
#########################
source 在当前的shell环境执行，而一般的脚本是另外启动一个shell执行
--------------------------------------------------------------
lily@willow:~$ cat test.sh
#!/bin/sh
export AA=BCCCCC

lily@willow:~$ ./test.sh
lily@willow:~$ echo $AA
BCCCCC
lily@willow:~$ ./testAA.sh

lily@willow:~$ ./testAA.sh

zh_CN.UTF-8
lily@willow:~$ source ./test.sh
lily@willow:~$ ./testAA.sh
BCCCCC
zh_CN.UTF-8
-------------------------------------------------------------------

enlarge the swap in linux
alhost ~]# dd if=/dev/zero of=/tmp/swap bs=1M count=6000
alhost ~]# ll -h /tmp/swap
alhost ~]# mkswap /tmp/swap
alhost ~]# fee -m
Swap:         2000
[root@localhost ~]# swapon /tmp/swap
[root@localhost ~]# free -m
             total       used       free     shared    buffers     cached
Mem:          3284       2570        714          0          9       2382
-/+ buffers/cache:        177       3106
Swap:         8000        493       7507
[root@localhost ~]# swapon -s
Filename                                Type            Size    Used    Priority
/dev/sda3                               partition       2048276 505000  -1
/tmp/swap                               file            6143992 0       -2


tee command redirect stderr and stdout to both terminal and file
ls aa bb 2>&1 |tee <filename>
tee -a : append to the file 


remove the space of the filename
find . -type f |while read file ; do mv "$file" `echo $file| tf -d ' '`;  done


wget can download all the web files in a direc:
eg.        -np
       --no-parent
           Do not ever ascend to the parent directory when retrieving recursively.  This is a useful
           option, since it guarantees that only the files below a certain hierarchy will be down-
           loaded.
       -r
       --recursive
           Turn on recursive retrieving.

       -l depth
       --level=depth
           Specify recursion maximum depth level depth.  The default maximum depth is 5.
       -c  conutinue try
wget -r -l 2 -np 
wget -c -r -np -k -L -p www.xxx.org/pub/path/
在下载时。有用到外部域名的图片或连接。如果需要同时下载就要用-H参数。

wget -np -nH -r --span-hosts www.xxx.org/pub/path/

wget -r -l1 --no-parent -nH --cut-dir=4   http://10.102.125.102:8011/results/ns30triplexs/2013-09-26--1053/TA_002147_01_0005/
get all the files in this dir TA_*_0005 using -r -l1 --no-parent
-nH --cut-dir limited the local dir architecture
-nH mans no http://10.102.125.102 as the parent dir
cut_dir means the dir after the link, here 4 dir will be cut,
So files only in that dir will be download in current dir.


wget -r -l1 --no-parent -nH --cut-dir=4 -A*.TTCN3.*  http://10.102.125.102:8011/results/ns30triplexs/2013-09-26--1053/TA_002147_01_0005/
-A means the wildcard of the files name 
TA_2.TTCN3.HLR.log
-c 断点续传
-r 递归下载，下载指定网页某一目录下（包括子目录）的所有文件
-nd 递归下载时不创建一层一层的目录，把所有的文件下载到当前目录
-np 递归下载时不搜索上层目录，如wget -c -r www.xxx.org/pub/path/
没有加参数-np，就会同时下载path的上一级目录pub下的其它文件
-k 将绝对链接转为相对链接，下载整个站点后脱机浏览网页，最好加上这个参数
-L 递归时不进入其它主机，如wget -c -r www.xxx.org/ 
如果网站内有一个这样的链接： 
www.yyy.org，不加参数-L，就会像大火烧山一样，会递归下载www.yyy.org网站
-p 下载网页所需的所有文件，如图片等
-A 指定要下载的文件样式列表，多个样式用逗号分隔
-i 后面跟一个文件，文件内指明要下载的URL

linux 网络 命令

ifconfig 控制网口 ，ip地址 ，掩码 
route 设置 显示 网关   或 netstat -r
域名服务器 在 /etc/resolve.conf


gvfs是gnome从2.22版本开始引入的高级特性，用于将各种存档文件（tar、gz、zip、iso等）和各种本地及网络协议（burn、cdda、ftp、http、webdav等）挂载为虚拟文件系统。
 
home目录下的.gvfs隐藏目录，挂载的存档文件已经作为一个目录放在里面了，任何应用程序都可以在这里访问存档里的文件了，唯一的缺憾是不可写。
对本地及网络协议的处理方法是类似的。以ftp访问为例，只要你是在nautilus资源管理器的地址栏输入ftp://ftp站点域名
或者用系统主菜单中的“连接到服务器”功能来访问的，那么该ftp连接已经自动被挂载到系统的“位置”菜单和nautilus资源管理器的位置栏里了，支持 gio的应用程序可以访问。如果你的系统中有gvfs-fuse的话，那么~/.gvfs下面也会出现对应于该ftp连接的一个目录，

tar命令 详解
x 表示 extract           c表示 compress
z 表示 处理文件格式为 tar.gz
 j 表示 处理 文件格式为tar.bz2

tar cizvf backup.tar.gz /var/cache/apt/archives --exclude=/var/cache/apt/archives/partial/* --exclude=/var/cache/apt/archives/lock

 tar xzvf backup.tar.gz -C ~/zxx

考贝 相同目录 名
比如： /tmp/test/cc1 ,另外 一个 文件 夹名字 /home/zxx/test/cc2/cc5/*
要 把/home/zxx/test 移动 到/tmp下 不能 用 mv命令 ，只能 佣
cp -R /home/zxx/test  /tmp/  原文件只能用删除 
install -d  /dec1/dec2/..    可以 一次创建多个文件


* how to rescue system from vmware
** mount vmware disk 
-----------
if 
vmware-mount 
faied
vmware-vdiskmanager.exe -R corrupt.vmdk

mount vmdk with LVM
Meltoner - Fri, 2012/06/29 - 00:48.
Hello,

if the vm's vmdk also has ..." LVM having 2 VG's, one for the root, and the other swap"...,you can access the filesystem with the following :

qemu-img convert -f vmdk turnkey-wordpress-11.3-lucid-x86.vmdk -O raw turnkey-core.raw

loopdev=$(losetup -s -f turnkey-core.raw)
kpartx -a $loopdev
//kpartx , create device maps from partition tables
mkdir rootfs
//lvscan - scan (all disks) for Logical Volumes
termcb:~ # lvscan
inactive '/dev/VolGroup00/LogVol00' [26.06 GB] inherit
inactive '/dev/VolGroup00/LogVol01' [1.75 GB] inherit

modprobe dm-mod
vgchange -ay
//vgchage --chage attributes of a volume grouop -a mean --available[e|l]{y|n}  y means yes

lvscan
#  ACTIVE            '/dev/turnkey/root' [17,00 GiB] inherit <---
#  ACTIVE            '/dev/turnkey/swap_1' [512,00 MiB] inherit

mount /dev/turnkey/root rootfs
cd rootfs

 
thanks to these posts:

http://www.turnkeylinux.org/blog/convert-vm-iso
http://pissedoffadmins.com/?p=481
http://www.fedoraforum.org/forum/archive/index.php/t-64964.html
?
Convert VM disk to raw image and mount it

First we need to get qemu-img, a tool bundled with qemu (KVM's virtualization backend) to convert the VM disk to a raw image, and TKLPatch, the TurnKey customization mechanism to package the ISO.

If you are not using a TurnKey installation, see the TKLPatch installation notes.

apt-get install qemu
apt-get install tklpatch
I'll show how to convert a VMWare VMDK image into raw disk format. If you are using a different virtualization platform such as Virtualbox, see this post on converting a VDI to a raw image.

qemu-img convert -f vmdk turnkey-core.vmdk -O raw turnkey-core.raw
Next, mount the raw disk as a loopback device.

mkdir turnkey-core.mount
mount -o loop turnkey-core.raw turnkey-core.mount
GOTCHA 1: If your VM has partitions, it's a little tricker. You'll need to setup the loop device, partition mappings and finally mount the rootfs partition. You will need kpartx to setup the mappings.

loopdev=$(losetup -s -f turnkey-core.raw)

apt-get install kpartx
kpartx -a $loopdev

# p1 refers to the first partition (rootfs)
mkdir turnkey-core.mount
mount /dev/mapper/$(basename $loopdev)p1 turnkey-core.mount
i-------i---------------i-----------
* Rescue the data from a corrupt os in vmware
Reboot from a rescue img 
http://netcologne.dl.sourceforge.net/project/systemrescuecd/sysresccd-x86/3.5.0/systemrescuecd-x86-3.5.0.iso
This iso generated from gentoo, it's very useful and you can get network working

mount the vmware virtual disk drive, 
usually it used as /dev/sda  /dev/sda1 /dev/sda2
lvscan
#  ACTIVE            '/dev/VolGroup00/LogVol00' [37,00 GiB] inherit <---
#  ACTIVE            '/dev/VolGroup00/LogVol01' [1.94 GiB] inherit
fdisk -l /dev/sda
Device      Boot    System     
/dev/sda1    *       Linux
/dve/sda2             Linux LVM

mount /dev/mapper/olGroup00/LogVol00 dir/
Thus we can got all files in dir

* try to repair the corrupt system
as rescue, don't mount the disk
but using  e2fsck  /dev/mapper/VolGroup00/LogVol00
------------------
intranet hostname resolve in linux
https://bbs.archlinux.org/viewtopic.php?id=146715
dhcp, samba
--------------------

** get a rescue disk to boot from, and mount it 



-------
Fixing the Can't move '.svn/tmp/entries' to '.svn/entries' error
By Javier Julio

I been having trouble deploying the latest version of a Flex Module due to an SVN error I had never come across before. I was trying to update the svn:externals property with a new URL but once I saved my change I would get the following error in Terminal:

Can抰 move ?svn/tmp/entries?to ?svn/entries? Operation not permitted

I tried running an svn cleanup command but no luck. After digging through Google I came across an excellent post (it抯 in Spanish) with a command to run that prevents the above error. Basically on the directory I was trying to run the svn propedit svn:externals . command, all I had to was run the following command first: 
chflags -R nouchg ./
nouchg  clear the user immutable flag (owner or super-user only

---------------------------------
===========
* mail in linux
Ubuntu) Send email from Terminal using Gmail or your domain.
echo "mail content"| mail -s mail subject?me@zhanxw.com


* one-line command
for in in `find ./ -name "*.o"` ; do nm "$i" |grep function_name; if [ $? == 0 ]; then echo $i; fi done


diff(standard) 
ignore extra space
-w option
ignore all kinds of space diffences
-B option
ignore all blank lines but not available with -u together
-I option
igonore lines which match the pattern 
diff -I '^#'
//ignore lines begin with "#"

cvs diff -u //it accespt any diff option

svn diff (set the diff command and parameter)
svn diff --diff-cmd diff -x -wu ...

vimdiff
set diffopt+=iwhite
vimdiff -c 'set diffopt+=iwhite' ...

patch
format of -u
@@ -18,7 +18,6 @@
   import from NAS        language "ASN.1:1997" all
   import from COMMONIEs  language "ASN.1:1997" all
   import from LCSAP      language "ASN.1:1997" all
-  import from EPC_CLI    language "ASN.1:1997" all;

 //  {
 //    type
@@ -97,11 +96,6 @@
     S102SubscriberParameters;
   }

-  import from EpcChinaLITCVRecords {
-    type
-    EpcCLISubscriberParameters;
-  }
-
   /*import from DiameterTCVRecords {
     type
     S6aSubscriberParameters, S6AParameters; }*/
@@ -223,6 +217,17 @@
   import from T3UtilityBox { group math; }
   //GtpV1 imports end

+  //ne3s imports begin
+  import from NE3STCVRecords all;
+  import from HTTPMsgTemplates all;
@@ -230,9 +235,6 @@
   import from DnsTCVRecords {type DnsSubscriberParametersMme};

   import from A21InitParameters {function f_S102SubscriberParameters;}
-
-
-
   function f_SubscriberParameters (inout template SubscriberParameters p_subscriberParameters) runs on BaseComp {
     var template S1SubscriberParameters        v_s1SubscriberParameters;
     var template SbcSubscriberParameters       v_sbcSubscriberParameters;



* linux 文本模式和图形模式的切换

从LINUX图形界面切换到文本模式
1.开机进入文本模式
如果想让开机自动进纯文本模式,修改/etc/inittab,找到其中的id:5:initdefault:,这行指示启动时的运行级是5,也就是图形模式,改成3就是文本模式了id:3:initdefault:,这是因为Linux操作系统有六种不同的运行级（run
level），在不同的运行级下，系统有着不同的状态，这六种运行级分别为：
0：停机（记住不要把initdefault 设置为0，因为这样会使Linux无法启动）
1：单用户模式，就像Win9X下的安全模式。
2：多用户，但是没有 NFS 。
3：完全多用户模式，标准的运行级。
4：一般不用，在一些特殊情况下可以用它来做一些事情。
5：X11，即进到 X-Window 系统。
6：重新启动 （记住不要把initdefault 设置为6，因为这样会使Linux不断地重新启动）。
其中运行级3就是我们要进入的标准Console字符界面模式。
2.强行退出X-Window进入文本模式
打开一个终端,输入init 3,(注意init后面有一个空格),等一会就进入了图形界面,以上方法切换后,窗口模式完全关闭.如果窗口中有文件未保存,将丢失.(用init 5可以回到图形界面,但原来的进程已死)
3.不退出X-Window进入文本模式
在X-Window图形操作界面中按"Alt+Ctrl+功能键Fn"(n=1~6),就可以进入文本模式界面。这就意味着你可以同时拥有X-Window加上6个文本模式界面，这是一件多么令人振奋的事情啊!按“Alt+Ctrl+F7”即可从文本模式界面回到X-Window图形操作界面。这时Linux默认打开7个屏
幕，编号为tty1~tty7。X-Window启动后，占用的是tty7号屏幕，tty1~tty6仍为字符界面屏幕。也就是说，用“Alt+Ctrl+Fn”组合键即可实现字符界面与X Window界面的快速切换。当X-Window由于自身或应用程序而失去响应或崩溃时，我们可以非常方便地退出X-Window进入Console进行故障处理，要做的只是按“Alt+Ctrl+Backspace”键
---------------------------------------------------------------------------------
1、如果在安装的时候你选择的默认格式是：桌面图形格式是：
ctrl+alt+f1 图形－－－＞文本格式
alt+f7        文本格式＝＝＝图形界面
2、如果在安装的时候你选择的默认格式是：文本格式
startx 即转换到图形界面 

在文本模式下启动图形模式下的程序
RKING=yes
HOSTNAME=localhost.localdomain
NETWORKING_IPV6=yes

需要export DISPLAY=:0
sudo ***/ui.app
这样图形界面就会运行此程序
ubuntu 下退出图形界面,exit the window manager
if openbox    openbox --exit
if gnome    service gdm stop
kill `pidof X`

* linux 系统usb热插拔检测

http://my.chinaunix.net/space.php?uid=22666248&do=blog&id=462715
qt USB热插拔检测
已有 41 次阅读  2011-06-27 07:15   标签:  转载 
LINUX2.6.13内核下是没有USB插拔机制的，即便是2.6.24内核依旧没有解决好USB插拔通知问题，而QT在版本4之前的版本都没有USB类的，没有USB插拔通知的方法，在QT4之后有了QDBUS，可通过QDBUS，进行USB热插拔
1、在QT4之后有了QDBUS，可通过QDBUS，进行USB热插拔
在pro文件中应该加入
QT +=dbus


复制代码

#include <QtDBus/QDBusConnection>
//以下为检测设备的插入
      QDBusConnection::systemBus().connect(    "org.freedesktop.Hal",
                        "/org/freedesktop/Hal/Manager",
                        "org.freedesktop.Hal.Manager",
                        "DeviceAdded",
                        this,
                        SLOT(slotDeviceAdded(QString )));
//以下为检查设备的拨出
    QDBusConnection::systemBus().connect(    "org.freedesktop.Hal",
                        "/org/freedesktop/Hal/Manager",
                        "org.freedesktop.Hal.Manager",
                        "DeviceRemoved",
                        this,
                        SLOT(slotDeviceRemoved(QString )));


在slotDeviceAdded(QString udi)函数中，要使用到


复制代码
    QDBusInterface device("org.freedesktop.Hal", udi, "org.freedesktop.Hal.Device" , QDBusConnection::systemBus());



通过HAL可以查询到设备为volume的设备，然后通过判断是否为/dev/sd*的设备，就可以判断出是否为U盘，然后调用mount就可以了。
这时记录下U盘的UDI，在检测到设备拨出时，再查询一下U盘的UDI是否还在，就知道U盘是否被拨出了。

这是采用QDBUS应该行的通的办法。
但是我没有去验证过，因为我目前还一直用的QT2.1.3,QTOPIA2.2的库，其中没有QDBUS，QT3也没有QDBUS类，没尝试过将QDBUS拿到QT2来用。

2、可以通过UDEV规则
通过UDEV规则编写，能够实现热插拔，但是还是不能做到即时通知

KERNEL=="sd[b-z]", NAME="%k", SYMLINK+="usb1", OPTIONS="last_rule"
#ACTION=="add", KERNEL=="sd[b-z][0-9]", SYMLINK+="usb%n", GROUP="users", NAME="%k"

#auto mount u disk
ACTION=="add", KERNEL=="sd[b-z][0-9]", RUN+="/bin/mkdir -p /mnt/usb1"

ACTION=="add", KERNEL=="sd[b-z][0-9]", RUN+="/bin/mount -t vfat /dev/%k /mnt/usb1"
ACTION=="add", KERNEL=="sd[b-z]", RUN+="/bin/mkdir -p /mnt/usb1"
ACTION=="add", KERNEL=="sd[b-z]",RUN+="/bin/mount -t vfat /dev/%k /mnt/usb1"

#autu mount sd card
ACTION=="add", KERNEL=="mmcblk[0-9][b-z][0-9]", RUN+="/bin/mkdir -p /mnt/mmc%n"

ACTION=="add", KERNEL=="mmcblk[0-9][b-z][0-9]", RUN+="/bin/mount -t vfat /dev/%k /mnt/mmc%n"

#ACTION=="add", KERNEL=="sd[a-z][0-9]", PROGRAM=="/lib/udev/vol_id -t %N", RESULT=="vfat", RUN+="/bin/mount -t vfat -o rw,noauto,sync,dirsync,noexec,nodev,noatime,dmask=000,fmask=111 /dev/%k /mnt/usb%n", OPTIONS="last_rule"

#ACTION=="add", KERNEL=="sd[a-z][0-9]", RUN+="/bin/mount -t auto -o rw,noauto,sync,dirsync,noexec,nodev,noatime /dev/%k /mnt/usb%n", OPTIONS="last_rule"
ACTION=="remove", KERNEL=="sd[b-z][0-9]", RUN+="/bin/umount -l /mnt/usb1"

ACTION=="remove", KERNEL=="sd[b-z][0-9]", RUN+="/bin/rm -rf /mnt/usb1", OPTIONS="last_rule"
ACTION=="remove",KERNEL=="sd[b-z}", RUN+="/bin/umount -l /mnt/usb1"
ACTION=="remove",KERNEL=="sd[b-z]",RUN+="/bin/rm -rf /mnt/usb1",OPTIONS="last_rule"

其实是通过UDEV进行自动挂载和卸载USB，其设备号是罗列的，自己可以根据情况变化。
该方法USB的挂载情况依然无法实时通知给QT应用程序。

3、修改启动文件
在/etc/init.d/rcS
添加
mount -t vfat /dev/sda1 /mnt/usb2
实现上机自动挂载
这个则只能实现U盘硬件自动启动挂载，离题都很远了。

4、采用定时机制
采用定时轮询方式，开启定时器，查询文件 /proc/MOUNT 或/proc/partition文件情况，读取相关信息，当该文件和分区情况有变化时，进行通知以及系统挂载。
该方法能解决相对问题，但增加系统负载，以及浪费定时器资源。

5、监测LINUX终端信息
LINUX 本身对USB是有监测的，现在的问题是如何将LINUX监测的终端输出结果，顺利的给QT程序读取，同时QT进行挂载以及卸载操作，该方法在尝试。怎么将 终端的输出结果顺利被LINUX进行检测到，采取的方法可以是LINUX对终端输出进行重定向，然后通过监测字段，发现USB变动情况。




http://zh-cn.w3support.net/index.php?db=so&id=469243
use D-Bus bindings and listen to DeviceAdded and DeviceRemoved signals.
 
import dbus
import gobject
class DeviceAddedListener:
def __init__(self):
  
You need to connect to Hal Manager using the system Bus.
self.bus = dbus.SystemBus();
self.hal_manager_obj = self.bus.get_object( "org.freedesktop.Hal",
                        "/org/freedesktop/Hal/Manager")
self.hal_manager = dubs.Interface(self.hal_manager_obj, "org.freedesktop.Hal.Manager")
self.hal_manager.connect_to_singal("DeviceAdded",self._filter)

def _filter(self,udi):
    device_obj=self.bus.get_object("org.freedesktop.Hal",udi)
device = dbus.Interface((device_obj,"org.freedesktop.Hal.Device")
if device.QueryCapability("volume"):
return self.do_something(device)


def do_something(self,volume):
 device_file = volume.GetProperty("block.device")
label = volume.Getproperty("volume.label")
fstype = volume.GetProperty("volume.fstype")




=================================

How can I listen D-Bus events for any USB device plug and unplug?

This is basically what I have now (also):

import dbus
import gobject
from dbus.mainloop.glib import DBusGMainLoop

def device_added_callback(device):
    print 'Device %s was added' % (device)

def device_changed_callback(device):
    print 'Device %s was changed' % (device)

#must be done before connecting to DBus
DBusGMainLoop(set_as_default=True)

bus = dbus.SystemBus()

proxy = bus.get_object("org.freedesktop.UDisks", 
                       "/org/freedesktop/UDisks")
iface = dbus.Interface(proxy, "org.freedesktop.UDisks.Device")

devices = iface.get_dbus_method('EnumerateDevices')()

print '%s' % (devices)

#addes two signal listeners
iface.connect_to_signal('DeviceAdded', device_added_callback)
iface.connect_to_signal('DeviceChanged', device_changed_callback)

#start the main loop
mainloop = gobject.MainLoop()
mainloop.run()


* linux 网络 命令

ifconfig 控制网口 ，ip地址 ，掩码 
route 设置 显示 网关   或 netstat -r
域名服务器 在 /etc/resolve.conf


gvfs是gnome从2.22版本开始引入的高级特性，用于将各种存档文件（tar、gz、zip、iso等）和各种本地及网络协议（burn、cdda、ftp、http、webdav等）挂载为虚拟文件系统。
 
home目录下的.gvfs隐藏目录，挂载的存档文件已经作为一个目录放在里面了，任何应用程序都可以在这里访问存档里的文件了，唯一的缺憾是不可写。
对本地及网络协议的处理方法是类似的。以ftp访问为例，只要你是在nautilus资源管理器的地址栏输入ftp://ftp站点域名
或者用系统主菜单中的“连接到服务器”功能来访问的，那么该ftp连接已经自动被挂载到系统的“位置”菜单和nautilus资源管理器的位置栏里了，支持 gio的应用程序可以访问。如果你的系统中有gvfs-fuse的话，那么~/.gvfs下面也会出现对应于该ftp连接的一个目录，

tar命令 详解
x 表示 extract           c表示 compress
z 表示 处理文件格式为 tar.gz
 j 表示 处理 文件格式为tar.bz2

tar cizvf backup.tar.gz /var/cache/apt/archives --exclude=/var/cache/apt/archives/partial/* --exclude=/var/cache/apt/archives/lock

 tar xzvf backup.tar.gz -C ~/zxx

考贝 相同目录 名
比如： /tmp/test/cc1 ,另外 一个 文件 夹名字 /home/zxx/test/cc2/cc5/*
要 把/home/zxx/test 移动 到/tmp下 不能 用 mv命令 ，只能 佣
cp -R /home/zxx/test  /tmp/  原文件只能用删除 
install -d  /dec1/dec2/..    可以 一次创建多个文件


* Linux   解压缩命令大全

linux下怎么解后缀名是gzip的文件？
1.以.a为扩展名的文件:
#tar xv file.a
2.以.z为扩展名的文件:
#uncompress file.Z
3.以.gz为扩展名的文件:
#gunzip file.gz
4.以.bz2为扩展名的文件:
#bunzip2 file.bz2
5.以.tar.Z为扩展名的文件:
#tar xvZf file.tar.Z
或 #compress -dc file.tar.Z | tar xvf -
6.以.tar.gz/.tgz为扩展名的文件:
#tar xvzf file.tar.gz
或 gzip -dc file.tar.gz | tar xvf -
7.以.tar.bz2为扩展名的文件:
#tar xvIf file.tar.bz2
或 bzip2 -dc file.tar.bz2 | xvf -
8.以.cpio.gz/.cgz为扩展名的文件:
#gzip -dc file.cgz | cpio -div
9.以.cpio/cpio为扩展名的文件:
#cpio -div file.cpio
或cpio -divc file.cpio
10.以.rpm为扩展名的文件安装:
#rpm -i file.rpm
11.以.rpm为扩展名的文件解压缩：
#rpm2cpio file.rpm | cpio -div
12.以.deb为扩展名的文件安装：
#dpkg -i file.deb
13.以.deb为扩展名的文件解压缩:
#dpkg-deb --fsys-tarfile file.deb | tar xvf - ar p
file.deb data.tar.gz | tar xvzf -
14.以.zip为扩展名的文件:
#unzip file.zip

在linux下解压Winzip格式的文件
　　要是装了jdk的话，可以用jar命令；还可以使用unzip命令。
直接解压.tar.gz文件
　　xxxx.tar.gz文件使用tar带zxvf参数，可以一次解压开。XXXX为文件名。 例如：
$tar zxvf xxxx.tar.gz
种压缩文件的解压（安装方法）

文件扩展名 解压（安装方法）

.a ar xv file.a
.Z uncompress file.Z
.gz gunzip file.gz
.bz2 bunzip2 file.bz2
.tar.Z tar xvZf file.tar.Z
compress -dc file.tar.Z | tar xvf -
.tar.gz/.tgz tar xvzf file.tar.gz
gzip -dc file.tar.gz | tar xvf -
.tar.bz2 tar xvIf file.tar.bz2
bzip2 -dc file.tar.bz2 | xvf -
.cpio.gz/.cgz gzip -dc file.cgz | cpio -div
.cpio/cpio cpio -div file.cpio
cpio -divc file.cpio
.rpm/install rpm -i file.rpm
.rpm/extract rpm2cpio file.rpm | cpio -div
.deb/install dpkg -i file.deb
.deb/exrtact dpkg-deb --fsys-tarfile file.deb | tar xvf -
ar p file.deb data.tar.gz | tar xvzf -
.zip unzip file.zip

bzip2 -d myfile.tar.bz2 | tar xvf

tar xvfz myfile.tar.bz2

x 是解压
v 是复杂输出
f 是指定文件
z gz格式

gzip
gzip[选项]要压缩（或解压缩）的文件名
-c将输出写到标准输出上，并保留原有文件。
-d将压缩文件压缩。
-l对每个压缩文件，显示下列字段：压缩文件的大小，未压缩文件的大小、压缩

比、未压缩文件的名字
-r递归式地查找指定目录并压缩或压缩其中的所有文件。
-t测试压缩文件是正完整。
-v对每一个压缩和解压缩的文件，显示其文件名和压缩比。
-num-用指定的数字调整压缩的速度。
举例：
把/usr目录并包括它的子目录在内的全部文件做一备份，备份文件名为usr.tar
tar cvf usr.tar /home
把/usr 目录并包括它的子目录在内的全部文件做一备份并进行压缩，备份文件名

是usr.tar.gz
tar czvf usr.tar.gz /usr
压缩一组文件，文件的后缀为tar.gz
#tar cvf back.tar /back/
#gzip -q back.tar
or
#tar cvfz back.tar.gz /back/
释放一个后缀为tar.gz的文件。
#tar zxvf back.tar.gz
#gzip back.tar.gz
#tar xvf back.tar 


* 修改img大小

dd
修改ramdisk大小的方法
分类： 嵌入式系统开发 2006-09-28 10:00 1970人阅读 评论(2) 收藏 举报
 修改ramdisk大小的方法
（1） 将原有RAM盘mount到某个目录下，如： /mnt/ramdisk
（2） 然后随便新建一个目录，将/mnt/ramdisk目录中的东西全部拷进去，并且加人自己新的东西，此时RAMDISK可以超过原来RAMDISK的大小限制； 
（3） 卸载掉/mnt/ramdisk： umount /mnt/ramdisk 
（4） mkdir /mnt/loop 
（5） dd if=/dev/zero of=/tmp/loop_tmp bs=1k count=10240 此时建立了loop设备的临时挂接点和一个大小为10M的临时文件，10M为新RAMDISK的大小； 
（6） /sbin/losetup /dev/loop0 /tmp/loop_tmp 将设备与临时文件联系起来。如果出现“ioctl: LOOP_SET_FD: 设备或资源忙”的提示，说明设备还和某一个文件联系，可以用/sbin/losetup /dev/loop0来看，并可用-d来删除；（7） /sbin/mke2fs –m 0 /dev/loop0   将loop0格式化为ext2文件系统 
（8） 接着把虚拟盘挂在节点/mnt上：mount /dev/loop0 /mnt/loop –t ext2 （9） 用cp –af 命令将自己要拷贝的目录下所有文件拷到 /mnt/loop下；
（10） 卸载：umount /mnt/loop，得到的/tmp/loop_tmp就是新的ramdisk；
（11） 压缩：gzip –v9 〉目标文件，生成的目标文件就是新RAMDISK；
（12） 到内核配置中，修改RAMDISK大小：
 Block devices ---> <*> RAM disk support (10240) Default RAM disk size，
 此处输入新的RAMDISK大小，修改后再重新编译内核

* 局域网 主机名解析问题
* setting local host's own hostname
cmd  hostname <hostname>
the config file:
/etc/sysconfig/network
HOSTNAME=<hostanem>
or in some system /ets/hostname
<hostname>

 
* Using DNS 
系统启动日志:  /var/log/messages
** linux accesss linux host:
if using dhcp, then make sure there's an entry in /etc/sysconfig/network
DHCP_HOSTNAME=hostname
/etc/hosts
127.0.0.1 local hostname
if static ip, then 
/etc/hosts
ipaddr  hostname

** linux access windows using hostname
smb configure
dns proxy = yes
wins server = 

** windows acesss linux host using hostname
if static ip address
Host文件放在系统盘的\Windows\system32\drivers\ect文件夹。名字是hosts
ipadress hostname

if dhcp client




** 通过hostname访问Linux主机
作者: Jan365  时间: 2010-04-18
操作系统:Windows + CentOS(VMWare虚拟机)
网络：局域网（DHCP）

因为经常要带着笔记本到不同的网络中工作，一般网络都有DHCP，但是每次分配的IP都不相同，访问虚拟机中的Linux就要先在虚拟机中登录，然后ifconfig查看ip地址，比较麻烦。

设想通过hostname来登录Linux主机，这样IP是动态的，但是hostname是固定的，方便很多。（听起来有点DNS的感觉，不过这只是局域网内部的。）

Windows系统的DHCP客户端会默认申请本机所设置的主机名(hostname)，而Linux的默认不会这样做。因此，要在配置文件中添加相应的项，向DHCP服务器请求想要的hostname:

[root@janzhen-vm ~]# vi /etc/sysconfig/networking/devices/ifcfg-eth0
 

添加：

DHCP_HOSTNAME=janzhen-VM(此处为所要申请的hostname)
 

重启网络服务后，在puTTY中就可以通过username@hostname来登录Linux了，不必先查看Linux的IP地址。

此外，设置hostname的配置文件为/etc/sysconfig/network，在DHCP环境下不必设置，而且设置了也不会生效



* Using WINS
(1) get linux hostname from windows
** linux hostname setting
if dns can't be updated in dhcpcd .
这种情况很常见，原因是dhcpcd无法更新dns。
简便的办法是用samba名代替域名：在linux上配置好samba (/etc/samba/smb.conf, 编辑netbios name = 你的机器名)。
windows在查找你的机器名时，除了做dns搜索，也会做wins搜索，有了samba就可以让windows找到了。
(/etc/samba/smb.conf, 编辑netbios name = 你的机器名)。

在 Windows 中的網路連線內容的 TCP/IP 中, 在 WINS 標籤頁可以設定是否要使用 NetBIOS over TCP/IP

(2) get windows hostname form linux
** windows setting 
no other wins support, wins server option
windows下可以直接主机名访问linux系统。
可以获得hostname的ip地址。
** linux setting
/etc/nsswitch.conf, 修改
hosts: file dns wins一行(加上wins)

s3) get linux hostname from other linux host
** linux access to access
如果要让其他linux机器也能找到，编辑(在其他linux机器上)：
/etc/nsswitch.conf, 修改
hosts: file dns wins一行(加上wins)
this will make name query via net-bios protocol(NBNS), name query NB hostname
-----------------------
1. wins in linux means the netbios name broadcast, and the broadcast address is not including
      nc  -l -p 6666              nc -u -l -p 5555 | nc 127.0.0.1 6666            nc -u 127.0.0.1 5555 
this host who send the broadcast package, in this example, the host 10.121.122.36 won't
receive this broadcast package. so assuce 10.121.122.36's hostname is cougar,
if you ping cougar in 10.121.122.36, 
there will be no response, for the broadcast package not including itself.
but if you ping cougar in other host who is the same network in 10.121.122.127, then
there will be replay in 10.121.122.36

2. if your host has a eth0:1, the ip alias, for example, if 36 has another ipaddr for example 37, the if you ping cougar in 36, there will be replay from 37.

3. ip host deceive
localhost if of cause 127.0.0.1, but in some host, maybe other host's ip addr.
for example, if one host's switch is wins first, then files.
and there's a host named localhost,then you will get response from the other host which name
is localhost.  
cat /etc/sysconfig/network
NETWORKING=yes
HOSTNAME=localhost.localdomain
NETWORKING_IPV6=yes
or cat /etc/hostname (in ubuntu system)
cat /etc/hosts
127.0.0.1 localhost.localdomain localhost
so if nsswith order is wins, files.
then you could get the localhost wrong ipaddress. so if something wrong in some application
,you can just specify localhost as 127.0.0.1

--------------------
14:10:49.824247 IP 10.121.122.36.60033 > 10.121.122.255.netbios-ns: NBT UDP PACKET(137): QUERY; REQUEST; BROADCAST
14:10:49.824250 IP 10.121.122.99.netbios-ns > 10.121.122.36.60033: NBT UDP PACKET(137): QUERY; POSITIVE; RESPONSE; UNICAST
-------------------
这种方法要求samba 3.0以上，或者检查需要有/etc/libnss_wins.so文件
linux也可以访问linux主机

** smb.conf configure as default is OK
for if no 
netbios name= ...
then your hostnmae will be used to as the netbios name in samba
but be sure smbd and nmbd all started


*** utilities to troubleshoot the problem
net lookup hostname (using wins, mdns,dns ..., but no netbios-ns)
nmblookup hostname (only using netbios)
nslookup hostname  (only using dns)

****nmblookup (using in linux to linux host by broadcasting)
broadcast the netbios package to all hosts whose ip is that.
Some problem in some network top structure. And maybe disable some broadcast package?
NBNS package format(NetBIOS Name Service)
udp/nbns/query hostname     BROARDCAST
THE MAC ADDR IS ff:ff:ff:ff:ff:ff
-----------------------------
12:44:37.068937 IP 10.121.122.12.netbios-ns > 10.121.122.127.netbios-ns: NBT UDP PACKET(137): QUERY; REQUEST; BROADCAST
12:44:36.983450 IP 10.121.122.36.netbios-ns > 10.121.122.12.50494: NBT UDP PACKET(137): QUERY; POSITIVE; RESPONSE; UNICAST
----------------------------------------
[liguo@localhost TTCN-3]$ ifconfig
eth0      Link encap:Ethernet  HWaddr 00:0C:29:3C:B1:8F
          inet addr:10.121.122.36  Bcast:10.121.122.127 
--------------------------------------------------------
[liguo@localhost TTCN-3]$ nmblookup butter
querying butter on 10.121.122.127
10.121.122.36 butter<00>
 [liguo@localhost TTCN-3]$ ping butter
ping: unknown host butter
 [liguo@localhost TTCN-3]$ net lookup butter
utils/net_lookup.c:net_llkup_host(55)
Didn't find butter#20
---------------------------------------------------
ping using other methods just as net lookup(wins server, dns server)

**** query on wins/dns server
using dns like message in udp/tcp package to reply the addr, usually in DNS server defined
in the LAN
 net lookup hostnmae
dns packet format
udp /dns/query/   to dns server(10.80.1.101), hostaddr
reply the   ipaddr
------------
12:44:36.988036 IP 10.121.122.36.32788 > apdc04.ap.tieto.com.domain:  61902+ PTR? 127.122.121.10.in-addr.arpa. (45)
12:44:37.028122 IP apdc04.ap.tieto.com.domain > 10.121.122.36.32788:  61902 NXDomain* 0/1/0 (133)
---------------------------------
since the dns server is a local machine, so it is a wins, so linux need to config the nsswitch add ths wins
hosts: file dns wins一行(加上wins)
===========
net lookup WW2002778
10.121.122.117
------------
nslookup WW2002778
Server: 10.80.1.101
Address: 10.80.1.101#53

Name: WW2002778.ap.tieto.co
Address: 10.121.122.117
============


* Troubleshooting Samba
** through log files
in smb.conf
log file = %m.log
//start smbd manually
smbd -l /usr/local/var/samba
log file = %S.log
log level = 3  ###the detail will be logged 
------------
[2013/04/19 12:41:50, 3] nmbd/nmbd_serverlistdb.c:write_browse_list(421)
  write_browse_list: Wrote browse list into file /var/cache/samba/browse.dat
[2013/04/19 12:42:30, 3] nmbd/nmbd_sendannounce.c:send_host_announcement(208)
  send_host_announcement: type 19a03 for host BUTTER on subnet 10.121.122.36 for workgroup AP
[2013/04/19 12:44:36, 3] nmbd/nmbd_incomingrequests.c:process_name_query_request(454)
  process_name_query_request: Name query from 10.121.122.12 on subnet 10.121.122.36 for name BUTTER<00>
[2013/04/19 12:44:36, 3] nmbd/nmbd_incomingrequests.c:process_name_query_request(569)
  OK
[2013/04/19 12:44:36, 3] nmbd/nmbd_sendannounce.c:send_host_announcement(208)
  send_host_announcement: type 19a03 for host BUTTER on subnet 10.121.122.36 for workgroup AP
[2013/04/19 12:44:36, 3] nmbd/nmbd_incomingrequests.c:process_name_query_request(454)
  process_name_query_request: Name query from 10.121.122.12 on subnet 10.121.122.36 for name AP<1d>
-------------------------
** through trace /tcpdump




* smbclient 使用
1，列出某个IP地址所提供的共享文件夹
smbclient -L 198.168.0.1 -U domainname/username%password
 
2,像FTP客户端一样使用smbclient
smbclient //192.168.0.1/tmp  -U domianname/username%password
 
执行smbclient命令成功后，进入smbclient环境，出现提示符： smb:\>
这里有许多命令和ftp命令相似，如cd 、lcd、get、megt、put、mput等。通过这些命令，我们可以访问远程主机的共享资源。
 
3,直接一次性使用smbclient命令
smbclient -c "ls"  //192.168.0.1/tmp  -U domainname/username%password
列出tmp文件夹下的内容
smbclient //192.168.0.1/tmp  -U domainname/username%password
smb:\>ls
功能一样的
 
例，创建一个共享文件夹
smbclient -c "mkdir share1"  //192.168.0.1/tmp  -U domainname/username%password
如果用户共享//192.168.0.1/tmp的方式是只读的，会提示
NT_STATUS_ACCESS_DENIED making remote directory \share1

把samba的共享mount 到本地文件夹下：
sudo mount -t smbfs //192.168.198.138/tests /mnt/tt -o username=zxxshare,password=123
sudo mount.cifs       //192.168.198.138/tests /mnt/tt -o username=zxxshare,password=123
mount -t cifs  //192.168.198.138/tests /mnt/tt -o username=zxxshare,password=123

guest access:
sudo mount -t cifs //netbiosname/sharename /media/sharename -o guest,iocharset=utf8
中文支持


sudo mount.cifs //10.120.152.7/home$/liguo /mnt/tt -o username=liguo,password=Password3,iocharset=utf8
sudo mount.cifs //10.121.122.117/redhat /mnt/tt -o username=guooolil,iocharset=utf8,nobrl,uid=snail, gid=snail, file_mode=0777, dir_mode=0777
nobrl: is for svn in mount volume
uid/gid/file_mde/dir_mode are for file permission in volume, otherwise, all write operation to
files will have no permission, sticky flag 


file name contains white space:
find ./ -maxdepth 1 -type d -print0|xargs  find -0 ls



=================================
zxx@gll-bac:/mnt/tt/My Documents$ cat -A /home/zxx/flist 
./bq.txt$
./1.txt$
./1 (M-eM-$M-^MM-dM-;M-6).txt$
./.wordump.txt$
./aa.txt$
lotus$
sumer 7$
frag$
chrasasum$
autum 8$
not fra$
plum$
early sumer 5$
yummy$
zxx@gll-bac:/mnt/tt/My Documents$ sed 's/ /\\&/g' /home/zxx/flist 
./bq.txt
./1.txt
./1\ (复件).txt
./.wordump.txt
./aa.txt
lotus
sumer\ 7
frag
chrasasum
autum\ 8
not\ fra
plum
early\ sumer\ 5
yummy


sudo mount.cifs //10.121.122.117/Redhat maybe -o user=guooolil,dom=AP,iocharset=utf8,uid=snail,gid=snail,dir_mode=0777,file_mode=0777,nobrl


* 窗口管理器和xinit配置

ctrl+alt+shift+F1 可以进入纯文本模式。
alt+F7
在此描述您的新便笺。


* 裁剪系统

linux是一个定制性非常强的东西，
裁剪一般是针对特定的功能，只运行一定的软件，这个时候，对于架构的把握，可以从需要实现的功能入手。比如上网本肯定需要浏览器，但这个浏览器肯定不是自己写，firefox.
如果想看运行firefox所依赖的东西的话，就用
apt-cache depends firefox|grep x11
这样就可以看到firefox是否需要x11
apt-cache depends firefox|grep -i gtk
apt-rdepends
linux下切换成root的方法：
sudo su
su - root sh -c "ls /"



* 查看磁盘空间和文件夹大小

 
du -sh dirname
取得文件夹大小  
du --max-depth=1 dirname 
查看当前文件夹下各个文件夹的大小
du -a  取得每一个文件大小信息
df  


* sort advantage usage
** sort -k meaning
*** sort -k 2
sort would have used all characters beginning in the second field and extending to the end of the line as the primary  key.
*** sort -k 2,2
sort would have used all characters only in the second field and not extending to the end of the line as the primary  key.


** sort -t meaning
in default, sort use blank as SEPERATOR, if you want to use something other thatn blank use -t
for ex
sort -t "|"  -k 2,2 
it means use "|" as the separator and column 2 as key

sort numerically on the second field and resolve ties by sorting alphabetically on the third and fourth characters of field five. Use ‘:’ as the field delimiter.

      sort -t : -k 2,2n -k 5.3,5.4

      Note that if you had written -k 2n instead of -k 2,2n sort would have used all characters beginning in the second field and extending to the end of the line as the primary numeric key. For the large majority of applications, treating keys spanning more than one field as numeric will not do what you expect.

i1, Justin Timberlake, Title 545, Price $7.30
2, Taylor Swift, Title 723, Price $7.90
3, Mick Jagger, Title 610, Price $7.90
4, Lady Gaga, Title 118, Price $7.30
5, Johnny Cash, Title 482, Price $6.50
6, Elvis Presley, Title 335, Price $7.30
7, John Lennon, Title 271, Price $7.90
8, Michael Jackson, Title 373, Price $5.50
i

uniq
        uniq [-cdu][-f,s,w N] [INPUT [OUTPUT]]

        Discard duplicate lines

     -c      Prefix lines by the number of occurrences
     -d      Only print duplicate lines
     -u      Only print unique lines
     -f N    Skip first N fields 
     -s N    Skip first N chars (after any skipped fields)
     -w N    Compare N characters in line

it could only work after sort results


** xargs
xargs is a shell command
it will read from stdin pip, make them with Space seperated.
for exam:
$cat dd
ab
cde
f

*** xarg -p will make the command exeution interactive

$cat dd|xargs -p echo 
n1@TeamCI-136 src]$ cat dfd|xargs -p  echo
echo ab cde f ?...y
ab cde f
from here we can see the argument list is seprated by space insted of newlin whcih is in orighinal dd file

*** -0 option
[admin1@TeamCI-136 src]$ find ./ -name "*.c" -exec echo '{}' \;
./M3APCodecAux.c
./M3APCodecT3.c
./M3APcodecs.c
[admin1@TeamCI-136 src]$ find ./ -name "*.c" -print0
./M3APCodecAux.c./M3APCodecT3.c./M3APcodecs.c
[admin1@TeamCI-136 src]$ find ./ -name "*.c" -print0|cat -A
./M3APCodecAux.c^@./M3APCodecT3.c^@./M3APcodecs.c^@
thie ^@ is a null character, so it means find's output will be seprated with null character with -print0 option instead of newline in default

So if xarg  using null character as saperater instead of newline/white space, using -0 to interpret it.
[admin1@TeamCI-136 src]$ find ./ -name "*.c" -print0|xargs -p  -0 echo
echo ./M3APCodecAux.c ./M3APCodecT3.c ./M3APcodecs.c ?...y
./M3APCodecAux.c ./M3APCodecT3.c ./M3APcodecs.c


*** -exec/-ok  option of find  VS. xargs
n1@TeamCI-136 src]$ find ./ -name "*.c" -ok echo '{}' \;
< echo ... ./M3APCodecAux.c > ? y
./M3APCodecAux.c
< echo ... ./M3APCodecT3.c > ? y
./M3APCodecT3.c
< echo ... ./M3APcodecs.c > ? y
./M3APcodecs.c

from here we can see that -exec will execute echo three times instead of once

* check whick shell currently working on
**    echo $0 - will print the program name... which in the case of shell is the actual shell

** $$ in shell is process id of current shell?
    ps  -ef | grep $$ | grep -v grep - will look for current process ID in the list of running processes. Current process being shell, it will include shell.

    This is not 100% reliable as you might have OTHER processes whose ps listing includes the same number as shell's process ID, especially if that ID is a small # (e.g. if shell's PID is "5", you may find processes called "java5" or "perl5" in the same grep output!). Which presents the second problem to "ps" approach, on top of the shell name being not always reliable.

**    echo $SHELL
 The path to the current shell is in SHELL variable for any shell. The caveat for the last one is that if you launch a shell explicitly as a subprocess (e.g. it's not your login shell) you will get you login shell's value instead - if that's a possibility, use the ps or $0 approach.

However, if the executable is not matching real shell (e.g. /bin/sh is actually bash or ksh), you need heuristics. Here are some environmental variables specific to various shells:

    $version is set on tcsh

    $BASH is set on bash

    $shell (lowercase) is set to actual shell name in csh or tcsh

    $ZSH_NAME is set on zsh

    ksh has $PS3 and $PS4 set, whereas normal Bourne shell (sh) only has $PS1 and $PS2 set. This generally seems like the hardest to distinguish - the ONLY difference in entire set of envionmental variables between sh and ksh we have installed on Solaris boxen is $ERRNO, $FCEDIT, $LINENO, $PPID, $PS3, $PS4, $RANDOM, $SECONDS, $TMOUT.


* man man  使用技巧

man [tobemaned]
eg. man sleep

The table below shows the section numbers of the manual followed by the
       types of pages they contain.

       1   Executable programs or shell commands
       2   System calls (functions provided by the kernel)
       3   Library calls (functions within program libraries)
       4   Special files (usually found in /dev)
       5   File formats and conventions eg /etc/passwd
       6   Games
       7   Miscellaneous  (including  macro  packages and conven‐
           tions), e.g. man(7), groff(7)
       8   System administration commands (usually only for root)
       9   Kernel routines [Non standard]

man sleep
--------------------------------------------------------
SLEEP(1)                         User Commands                        SLEEP(1)

NAME
       sleep - delay for a specified amount of time
-------------------------------------------------------------

man  -a sleep
---------------
SLEEP(3)                   Linux Programmer's Manual                  SLEEP(3)

NAME
       sleep - Sleep for the specified number of seconds

SYNOPSIS
       #include <unistd.h>

       unsigned int sleep(unsigned int seconds);
--------------------------------------------------------------



man -k sleep  //make a list
------------------------------
clock_nanosleep (2)  - high-resolution sleep with specifiable clock
nanosleep (2)        - high-resolution sleep
rtcwake (8)          - enter a system sleep state until specified wakeup time
sleep (1)            - delay for a specified amount of time
sleep (3)            - Sleep for the specified number of seconds
usleep (3)           - suspend execution for microsecond intervals
---------------------------------------

zxx@zxx-desktop:/usr/include/X11$ man -f sleep
----------------------------------------------------
sleep (3)            - Sleep for the specified number of seconds
sleep (1)            - delay for a specified amount of time
-----------------------------------------------------

man 3 sleep 


man --regex ".*map.*window"
---------------------------------------------------
--Man-- 下一页: XMapWindow(3) [ 查看 (return) | 跳过 (Ctrl-D) | 退出 (Ctrl-C) ]

--Man-- 下一页: XUnmapWindow(3) [ 查看 (return) | 跳过 (Ctrl-D) | 退出 (Ctrl-C) ]

--Man-- 下一页: XGetWMColormapWindows(3) [ 查看 (return) | 跳过 (Ctrl-D) | 退出 (Ctrl-C) ]
--Man-- 下一页: XtSetWMColormapWindows(3) [ 查看 (return) | 跳过 (Ctrl-D) | 退出 (Ctrl-C) ]
---------------------------------------------------------------------

zxx@gll-bac:/usr/share/man$ man -k ".*map.*window"
-----------------------------------------------------
atobm (1)            - bitmap editor and converter utilities for the X Window System
bitmap (1)           - bitmap editor and converter utilities for the X Window System
bmtoa (1)            - bitmap editor and converter utilities for the X Window System
XGetWMColormapWindows (3) - set or read a window's WM_COLORMAP_WINDOWS property
XMapRaised (3)       - map windows
XMapSubwindows (3)   - map windows
XMapWindow (3)       - map windows
XSetWMColormapWindows (3) - set or read a window's WM_COLORMAP_WINDOWS property
XtSetWMColormapWindows (3) - Set the value of the WM_COLORMAP_WINDOWS property
XUnmapSubwindows (3) - unmap windows
XUnmapWindow (3)     - unmap windows
--------------------------------------------------------------------

//find x11 programing

zxx@gll-bac:/usr/share/man$ man -a  -w XMapWindow
/usr/share/man/man3/XMapWindow.3.gz
zxx@gll-bac:/usr/share/man$ man -a  -w XUnMapWindow
/usr/share/man/man3/XUnmapWindow.3.gz

zxx@gll-bac:/usr/share/man/man3$ ls |grep XQuery
DMXQueryExtension.3.gz
DMXQueryVersion.3.gz
XQueryBestCursor.3.gz
XQueryBestSize.3.gz
XQueryBestStipple.3.gz
XQueryBestTile.3.gz
XQueryColor.3.gz
XQueryColors.3.gz
XQueryDeviceState.3.gz
XQueryExtension.3.gz
XQueryFont.3.gz
XQueryKeymap.3.gz
XQueryPointer.3.gz
XQueryTextExtents16.3.gz
XQueryTextExtents.3.gz
XQueryTree.3.gz


处理mandoc成文本
man ls | col -b > man.txt 
man -t sleep |ps2pdf - ~/doc.pdf

一个应用程序将会有很多window
lily@ubuntu:~/x11-utils-7.6+1/xwininfo$ xwininfo -root -all |grep -i firefox
     0x4004566 "Firefox": ("Popup" "Firefox")  219x138+412+340  +412+340
     0x4000b9b "Firefox": ("Popup" "Firefox")  200x200+0+0  +0+0
     0x40008ca "Firefox": ()  10x10+-100+-100  +-100+-100
     0x400029e "Firefox": ("Popup" "Firefox")  237x267+40+78  +40+78
     0x40001c0 "Firefox": ("Popup" "Firefox")  200x200+0+0  +0+0
     0x40000b3 "Firefox": ("firefox-bin" "Firefox-bin")  200x200+0+0  +0+0
     0x40000aa "Firefox": ("firefox-bin" "Firefox-bin")  200x200+0+0  +0+0
     0x40000a9 "Firefox": ()  10x10+-100+-100  +-100+-100
     0x40000a8 "Firefox": ()  10x10+-100+-100  +-100+-100
     0x40000a7 "Firefox": ()  10x10+-100+-100  +-100+-100
     0x4000077 (has no name): ("Toplevel" "Firefox")  200x200+0+0  +0+0
     0x4000001 "Firefox": ("firefox-bin" "Firefox-bin")  10x10+10+10  +10+10
        0x400009c "bufexplorer.zip - Buffer Explorer / Browser : vim online - Mozilla Firefox": ("Navigator" "Firefox")  429x440+1+29  +-42+88
---------------------------------------------------------------
在这里可用的window id 是   0x400009c  这里主要是看尺寸得到最大的尺寸就是 429*440

在有window manager的系统里wmctrl -l会列出所有应用的window id，但是如果没有窗口管理器就必须用
xwininfo -root -all 适用于没有窗口管理器的情况，需要分析出application window
wmctrl 是通过  
    if ((client_list = (Window *)get_property(disp, DefaultRootWindow(disp), 
                    XA_WINDOW, "_NET_CLIENT_LIST", size)) == NULL) {
        if ((client_list = (Window *)get_property(disp, DefaultRootWindow(disp), 
                        XA_CARDINAL, "_WIN_CLIENT_LIST", size)) == NULL) {
得到client window list的。这里返回的直接是application的根window。

xwininfo 也可以用鼠标取得某个application的window id，原理是通过WM_STATE,通过遍历root的children和descendants来查看有WM_STATE,PROPEty 的window来取得id
 atom_wm_state = Get_Atom(dpy, "WM_STATE");
 Window_Has_Property(dpy, children[i], atom_wm_state)
 xlsclients -l 也是通过查看有WM_STATE,PROPEty 的window来取得id的，这在window不是active状态得到的值是错误的。
（http://tronche.com/gui/x/icccm/sec-4.html#s-4.1.3.1）
 4.1.3.1. WM_STATE Property
The window manager will place a WM_STATE property (of type WM_STATE) on each top-level client window that is not in the Withdrawn state. Top-level windows in the Withdrawn state may or may not have the WM_STATE property. Once the top-level window has been withdrawn, the client may re-use it for another purpose. Clients that do so should remove the WM_STATE property if it is still present. 
Some clients (such as xprop) will ask the user to click over a window on which the program is to operate. Typically, the intent is for this to be a top-level window. To find a top-level window, clients should search the window hierarchy beneath the selected location for a window with the WM_STATE property. This search must be recursive in order to cover all window manager reparenting possibilities. If no window with a WM_STATE property is found, it is recommended that programs use a mapped child-of-root window if one is present beneath the selected location. 



* redirect tricks of dash/hyphen "-"
some shell command will accept "-" as a parameter, and "-" means stdandard
out or standard in 
** standard in
gzip -dc /cdrom/cdrom0/file.tar.gz | tar xvf –
// here - means the stardard in that means standard output of gzip command

** standard out
tcpdump ... -w - |tee <filename> |tcpdump -r -
this command will make tcpdump output both to standard output and a file.
the first hypen after -w means the standard output, and it will be as a input of tee command, Normally it's enough, but when tcpdmp -w 's output format
need to be interpretted by tcpdump -r command 

** start a shell script in daemon way
say if you have a server prgram, but its not a daemon program, you start it in shell background,
like "cow -rc ~/.cow/rc &", but when the ssh terminal disconnect, it will be killed also.
===============================================
setsid myscript.sh >/dev/null 2>&1 < /dev/null &
==============================================
start a new session to run the script and redirect stdin/error/out to /dev/null and in background
if you want to run when computer startup, put in /etc/rc.lcoal file.



